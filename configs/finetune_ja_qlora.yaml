# SO8T日本語ファインチューニング設定（QLoRA 8bit）
# 防衛・航空宇宙・運輸向けセキュアLLM
# RTX3080 12GB対応

# モデル設定
model:
  base_model: "../Phi-4-mini-instruct"
  so8t_integrated_model: "./phi4_so8t"
  model_type: "phi3"
  
  # SO8T設定
  so8t:
    enabled: true
    init_scale: 0.05
    orthogonal_reg: 1.0e-4
    
  # 量子化設定（QLoRA）
  quantization:
    load_in_8bit: true
    llm_int8_threshold: 6.0
    llm_int8_has_fp16_weight: false
    
  # LoRA設定
  lora:
    r: 64                    # LoRAランク
    lora_alpha: 128          # LoRAスケーリング係数
    target_modules:          # LoRA適用対象
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
      - "gate_proj"
      - "up_proj"
      - "down_proj"
    lora_dropout: 0.05
    bias: "none"
    task_type: "CAUSAL_LM"

# データ設定
data:
  # 訓練データ
  train_data:
    - "data/japanese_collected.jsonl"
    - "data/synthetic_data.jsonl"
    - "data/japanese_complex_dataset.jsonl"
  
  # 検証データ
  val_data: "data/validation_burnin_test_japanese.json"
  
  # データ処理
  max_seq_length: 2048
  preprocessing_num_workers: 4
  
  # データ混合比率
  mixing_ratios:
    japanese_collected: 0.4
    synthetic_data: 0.4
    japanese_complex: 0.2

# 学習設定
training:
  # 基本設定
  output_dir: "./checkpoints/so8t_phi4_ja"
  num_train_epochs: 3
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 8
  
  # 最適化
  learning_rate: 2.0e-4
  weight_decay: 0.01
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-8
  max_grad_norm: 1.0
  
  # スケジューラ
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.1
  warmup_steps: 0  # warmup_ratioを使用
  
  # 精度
  fp16: false
  bf16: true
  tf32: true
  
  # ログ・保存
  logging_steps: 10
  save_steps: 500
  save_total_limit: 5
  save_strategy: "steps"
  evaluation_strategy: "steps"
  eval_steps: 500
  
  # その他
  report_to: ["tensorboard"]
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false
  
  # メモリ効率化
  gradient_checkpointing: true
  optim: "paged_adamw_8bit"
  
  # 電源断リカバリー
  resume_from_checkpoint: true
  save_on_each_node: true

# PET正規化設定
pet:
  enabled: true
  lambda_exploration: 0.01
  lambda_transition: 0.05
  lambda_stabilization: 0.1
  exploration_ratio: 0.2
  transition_ratio: 0.4
  stabilization_ratio: 0.4
  huber_delta: 0.0
  clip_gradient: true
  max_gradient_norm: 1.0
  log_every_n_steps: 100

# 評価設定
evaluation:
  # メトリクス
  metrics:
    - "perplexity"
    - "loss"
    - "accuracy"
  
  # ドメイン別評価
  domain_evaluation: true
  domains:
    - "defense"
    - "aerospace"
    - "transport"
    - "safety"
  
  # 長文評価
  long_context_test: true
  long_context_lengths: [512, 1024, 2048]

# ハードウェア設定
hardware:
  device: "cuda"
  num_gpus: 1
  gpu_memory_limit: 11  # GB (RTX3080 12GBの場合)
  
  # CUDA最適化
  cuda_optimization:
    cudnn_benchmark: true
    cudnn_deterministic: false
    allow_tf32: true

# 安全性設定
safety:
  # 三重推論有効化
  triple_reasoning_enabled: true
  
  # 判定閾値
  thresholds:
    allow_confidence: 0.8
    deny_confidence: 0.9
    escalation_default: true
  
  # 監査ログ
  audit_logging: true
  audit_db_path: "./database/so8t_compliance.db"

# その他
misc:
  seed: 42
  deterministic: false  # 速度優先
  num_workers: 4
  prefetch_factor: 2
  pin_memory: true

