# SO8T Inference Configuration
# Configuration for SO8T Safe Agent inference

# Model configuration
model:
  base_model_name: "Qwen/Qwen2.5-7B-Instruct"
  checkpoint_path: "checkpoints/so8t_qwen2.5-7b_sft_fp16"
  use_gguf: false
  gguf_path: null
  device: "auto"
  torch_dtype: "float16"

# Inference configuration
inference:
  max_tokens: 2048
  temperature: 0.7
  top_p: 0.9
  top_k: 50
  repetition_penalty: 1.1
  do_sample: true
  num_beams: 1
  early_stopping: false
  pad_token_id: null
  eos_token_id: null
  max_new_tokens: 512

# Safety configuration
safety:
  safety_threshold: 0.8
  confidence_threshold: 0.7
  enable_safety_checks: true
  require_human_approval: true
  max_escalation_rate: 0.3

# Logging configuration
logging:
  log_level: "INFO"
  log_file: "logs/agent_runtime.log"
  audit_log: "logs/audit.jsonl"
  max_log_size: "100MB"
  backup_count: 5
  enable_console_logging: true
  enable_file_logging: true

# Escalation configuration
escalation:
  enable_notifications: true
  notification_webhook: null
  email_notifications: false
  escalation_timeout: 300  # seconds
  notification_retry_attempts: 3
  notification_retry_delay: 60  # seconds

# Performance configuration
performance:
  enable_gpu_optimization: true
  enable_memory_optimization: true
  max_batch_size: 4
  enable_caching: true
  cache_size: 1000
  cache_ttl: 3600  # seconds

# Monitoring configuration
monitoring:
  enable_metrics: true
  metrics_port: 8080
  health_check_interval: 30  # seconds
  enable_performance_tracking: true
  enable_error_tracking: true

# Security configuration
security:
  enable_input_validation: true
  enable_output_sanitization: true
  max_input_length: 4096
  max_output_length: 2048
  enable_rate_limiting: true
  rate_limit_requests_per_minute: 60

# API configuration (if using FastAPI)
api:
  host: "0.0.0.0"
  port: 8000
  workers: 1
  reload: false
  log_level: "info"
  enable_cors: true
  cors_origins: ["*"]
  enable_docs: true
  docs_url: "/docs"
  redoc_url: "/redoc"
