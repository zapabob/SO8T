{
  "batch_size": 2,
  "gradient_accumulation": 8,
  "learning_rate": 2e-4,
  "weight_decay": 0.01,
  "warmup_steps": 200,
  "max_steps": 2000,
  "bf16": false,
  "fp16": true,
  "checkpoint_interval": 200,
  "pet_schedule": [0.3, 0.7],
  "clip_grad_norm": 1.0
}
