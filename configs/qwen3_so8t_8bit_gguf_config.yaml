# Qwen3-4B-Thinking-2507-FP8 SO8T Transformer 8bit量子化GGUF変換設定
# RTX3080 12GBでSO8T Transformerを8bit量子化してGGUF形式に変換

model:
  # モデルパス
  model_path: "Qwen3-4B-Thinking-2507-FP8"
  
  # Basic model parameters (Qwen3-4B-Thinking-2507-FP8準拠)
  vocab_size: 151936
  hidden_size: 2560
  intermediate_size: 9728
  num_hidden_layers: 36
  num_attention_heads: 32
  num_key_value_heads: 8
  head_dim: 128
  hidden_act: "silu"
  max_position_embeddings: 262144
  rms_norm_eps: 1e-6
  rope_theta: 5000000.0
  attention_bias: false
  attention_dropout: 0.0
  use_cache: true
  tie_word_embeddings: true
  
  # Tokenizer
  tokenizer_name: "Qwen/Qwen2.5-7B-Instruct"  # 互換性のため

# SO8T specific parameters
so8t:
  rotation_dim: 8
  safety_weight: 0.1
  cmd_weight: 0.9
  pet_lambda: 0.01
  group_monitoring: true
  gradient_checkpointing: true
  use_flash_attention: false
  triality_symmetry: true
  multihead_attention: true
  cross_head_interaction: true
  non_commutative_gates: true
  vector_representation: true
  spinor_plus_representation: true
  spinor_minus_representation: true

# 8bit量子化設定
quantization:
  load_in_8bit: true
  llm_int8_enable_fp32_cpu_offload: true
  llm_int8_threshold: 6.0
  llm_int8_has_fp16_weight: false
  llm_int8_skip_modules: ["lm_head", "task_head", "safety_head", "authority_head"]
  torch_dtype: "bfloat16"
  device_map: "auto"
  trust_remote_code: true
  low_cpu_mem_usage: true
  use_cache: true

# GGUF変換設定
gguf:
  model_type: "qwen3_so8t_transformer"
  quantization: "8bit"
  dtype: "bfloat16"
  output_dir: "D:/models/qwen3_so8t_8bit_gguf"
  filename: "qwen3_so8t_transformer_8bit.gguf"
  include_metadata: true
  include_tokenizer: true
  include_weights: true
  preserve_so8t_structure: true
  preserve_triality_symmetry: true

# メモリ最適化設定
memory:
  max_memory: "12GB"
  gpu_memory_fraction: 0.9
  cpu_offload: true
  gradient_checkpointing: true
  use_cache: true
  offload_folder: "./offload_cache"

# ログ設定
logging:
  level: "INFO"
  log_file: "logs/qwen3_so8t_gguf_conversion.log"
  console_output: true
  progress_bar: true
  tqdm_enabled: true

# 変換設定
conversion:
  batch_size: 1
  max_sequence_length: 2048
  save_intermediate: true
  verify_so8t_structure: true
  verify_triality_symmetry: true
  compression_level: 6
