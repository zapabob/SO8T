# SO8T Training Configuration
# Configuration for QLoRA training of SO8T Safe Agent

# Model configuration
model:
  base_model_name: "models/Qwen2.5-7B-Instruct"
  task_head_hidden_size: 4096
  safety_head_hidden_size: 2048
  safety_num_classes: 3  # ALLOW, REFUSE, ESCALATE
  rationale_max_length: 128  # Reduced for memory efficiency
  pet_lambda: 0.1
  safety_threshold: 0.8
  vocab_size: 151936  # Qwen2.5-7B-Instruct vocab size

# Training configuration - RTX3060 (12GB) 8bit QLoRA optimized
training:
  num_epochs: 2  # メモリ制約のためエポック数を削減
  batch_size: 1  # 最小バッチサイズ（必須）
  gradient_accumulation_steps: 8  # 実質バッチサイズ8
  learning_rate: 2e-4  # 8bit QLoRA用学習率
  safety_learning_rate: 1e-4  # 安全ヘッドの学習率
  weight_decay: 0.0  # 8bit QLoRAでは重み減衰を無効化
  max_grad_norm: 0.3  # 勾配クリッピングを強化
  warmup_steps: 5
  lr_scheduler_type: "cosine"
  save_steps: 20  # より頻繁に保存
  eval_steps: 20
  logging_steps: 1  # より頻繁にログ出力
  save_total_limit: 2
  load_best_model_at_end: true
  metric_for_best_model: "safety_score"
  greater_is_better: true
  dataloader_pin_memory: false  # メモリ効率化
  dataloader_num_workers: 0  # メモリ効率化

# QLoRA configuration
qlora:
  r: 16
  lora_alpha: 32
  lora_dropout: 0.1
  target_modules:
    - "q_proj"
    - "v_proj"
    - "k_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  bias: "none"
  task_type: "CAUSAL_LM"

# Quantization configuration
quantization:
  load_in_4bit: true
  bnb_4bit_use_double_quant: true
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_compute_dtype: "float16"

# Loss configuration
loss:
  task_weight: 1.0
  safety_weight: 2.0
  rationale_weight: 1.0
  pet_weight: 0.1
  safety_penalty_weight: 5.0
  escalate_reward_weight: 2.0
  pet_lambda: 0.1
  safety_threshold: 0.8

# Data configuration
data:
  train_data_path: "data/so8t_seed_dataset.jsonl"
  val_data_path: "data/so8t_seed_dataset.jsonl"
  test_data_path: "data/so8t_seed_dataset.jsonl"
  max_length: 1024  # Reduced for memory efficiency
  include_rationale: true
  num_workers: 0
  pin_memory: true

# Early stopping configuration
early_stopping:
  enabled: true
  patience: 3
  min_delta: 0.01
  monitor: "safety_score"
  mode: "max"

# Weights & Biases configuration
wandb:
  enabled: false
  project: "so8t-safe-agent"
  entity: null
  name: null
  tags:
    - "so8t"
    - "safety"
    - "qlora"

# Output configuration
output:
  output_dir: "checkpoints/so8t_qwen2.5-7b_sft"
  logging_dir: "logs/training"
  seed: 42
  dataloader_num_workers: 0
  remove_unused_columns: false
  fp16: true
  bf16: false
  tf32: false
  dataloader_pin_memory: true
  report_to: ["tensorboard"]
