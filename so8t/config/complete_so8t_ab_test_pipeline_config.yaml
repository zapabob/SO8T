# SO8T完全統合A/Bテストパイプライン設定ファイル

# 基本設定
session_id_format: "%Y%m%d_%H%M%S"
output_base_dir: "D:/webdataset"
checkpoint_dir: "D:/webdataset/checkpoints/complete_so8t_ab_test"

# Model A設定（ベースSO8Tモデル）
model_a:
  base_model: "models/Borea-Phi-3.5-mini-Instruct-Jp"
  description: "Borea-Phi-3.5-mini-Instruct-Jp with modeling_phi3_so8t.py (no retraining)"

# Model B設定（SO8T再学習モデル）
model_b:
  base_model: "models/Borea-Phi-3.5-mini-Instruct-Jp"
  description: "Borea-Phi-3.5-mini-Instruct-Jp with SO8T retraining (QLoRA/fine-tuning)"

# データセット設定
dataset:
  paths:
    - "D:/webdataset/processed/four_class"
  format: "jsonl"

# 学習設定
training:
  config: "configs/train_so8t_phi3_qlora.yaml"
  use_qlora: true
  use_full_finetuning: false

# GGUF変換設定
gguf:
  convert_script: "external/llama.cpp-master/convert_hf_to_gguf.py"
  quantizations:
    - "f16"
    - "q8_0"
    # Note: q4_k_m is not supported by convert_hf_to_gguf.py
    # Supported types: f32, f16, bf16, q8_0, tq1_0, tq2_0, auto

# Ollama設定
ollama:
  model_a_name: "borea-phi35-so8t-base"
  model_b_name: "borea-phi35-so8t-retrained"
  modelfile_dir: "modelfiles"

# A/Bテスト設定
ab_test:
  test_data: "D:/webdataset/processed/four_class"
  max_samples: 50  # テストサンプル数（時間短縮のため）

# 可視化設定
visualization:
  output_dir: "visualizations"
  plot_format: "png"
  dpi: 300

# デバイス設定
device: "cuda"  # cuda or cpu

