#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SO8T Automatic Pipeline Runner
3åˆ†é–“éš”ã§SO8Tãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã€ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç®¡ç†
"""

import os
import sys
import time
import signal
import atexit
from pathlib import Path
from datetime import datetime, timedelta
import logging
import subprocess
import psutil
import argparse

# SO8Tãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from utils.checkpoint_manager import RollingCheckpointManager
except ImportError as e:
    print(f"Import error: {e}")
    sys.exit(1)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/so8t_auto_pipeline.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class SO8TAutoPipelineRunner:
    """
    SO8Tè‡ªå‹•ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¯ãƒ©ã‚¹
    3åˆ†é–“éš”ã§å®Ÿè¡Œã—ã€ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç®¡ç†
    """

    def __init__(self,
                 pipeline_script: str = "scripts/training/train_borea_phi35_so8t_ppo.py",
                 dataset_path: str = "data/so8t_quadruple_dataset.jsonl",
                 output_dir: str = "outputs/so8t_auto_pipeline",
                 checkpoint_dir: str = "checkpoints/so8t_rolling",
                 interval_minutes: int = 3,
                 max_checkpoints: int = 5,
                 max_iterations: int = None):
        """
        åˆæœŸåŒ–

        Args:
            pipeline_script: å®Ÿè¡Œã™ã‚‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
            dataset_path: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            checkpoint_dir: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            interval_minutes: å®Ÿè¡Œé–“éš”ï¼ˆåˆ†ï¼‰
            max_checkpoints: æœ€å¤§ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ•°
            max_iterations: æœ€å¤§å®Ÿè¡Œå›æ•°ï¼ˆNoneã§ç„¡é™ï¼‰
        """
        self.pipeline_script = Path(pipeline_script)
        self.dataset_path = Path(dataset_path)
        self.output_dir = Path(output_dir)
        self.checkpoint_dir = Path(checkpoint_dir)
        self.interval_minutes = interval_minutes
        self.max_checkpoints = max_checkpoints
        self.max_iterations = max_iterations

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)

        # ãƒ­ãƒ¼ãƒªãƒ³ã‚°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        self.checkpoint_manager = RollingCheckpointManager(
            base_dir=self.checkpoint_dir,
            max_keep=self.max_checkpoints,
            save_interval_sec=180  # 3åˆ†
        )

        # å®Ÿè¡ŒçŠ¶æ…‹
        self.running = False
        self.iteration_count = 0
        self.last_execution_time = None

        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)

        # çµ‚äº†æ™‚å‡¦ç†
        atexit.register(self._cleanup)

        logger.info("SO8T Auto Pipeline Runner initialized")
        logger.info(f"Pipeline script: {self.pipeline_script}")
        logger.info(f"Dataset: {self.dataset_path}")
        logger.info(f"Output dir: {self.output_dir}")
        logger.info(f"Checkpoint dir: {self.checkpoint_dir}")
        logger.info(f"Interval: {self.interval_minutes} minutes")
        logger.info(f"Max checkpoints: {self.max_checkpoints}")

    def start(self):
        """è‡ªå‹•å®Ÿè¡Œã‚’é–‹å§‹"""
        logger.info("=== SO8T Auto Pipeline Started ===")
        self.running = True

        try:
            while self.running:
                # æœ€å¤§å®Ÿè¡Œå›æ•°ãƒã‚§ãƒƒã‚¯
                if self.max_iterations and self.iteration_count >= self.max_iterations:
                    logger.info(f"Reached maximum iterations ({self.max_iterations})")
                    break

                # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯
                if not self._check_system_ready():
                    logger.warning("System not ready, waiting...")
                    time.sleep(60)  # 1åˆ†å¾…æ©Ÿ
                    continue

                # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
                self._execute_pipeline()

                # å®Ÿè¡Œã‚«ã‚¦ãƒ³ãƒˆæ›´æ–°
                self.iteration_count += 1
                self.last_execution_time = datetime.now()

                # æ¬¡å›å®Ÿè¡Œã¾ã§å¾…æ©Ÿï¼ˆæœ€å¤§å®Ÿè¡Œå›æ•°ã«é”ã—ã¦ã„ãªã„å ´åˆï¼‰
                if self.running and (not self.max_iterations or self.iteration_count < self.max_iterations):
                    self._wait_for_next_execution()

        except KeyboardInterrupt:
            logger.info("Received keyboard interrupt")
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
        finally:
            logger.info("=== SO8T Auto Pipeline Stopped ===")

    def stop(self):
        """å®Ÿè¡Œã‚’åœæ­¢"""
        logger.info("Stopping SO8T Auto Pipeline...")
        self.running = False

    def _execute_pipeline(self):
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ"""
        execution_id = f"iteration_{self.iteration_count:04d}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        logger.info(f"=== Executing Pipeline {execution_id} ===")

        try:
            # å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰
            cmd = [
                sys.executable,  # Pythonå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«
                str(self.pipeline_script),
                "--dataset_path", str(self.dataset_path),
                "--output_dir", str(self.output_dir / execution_id),
                "--checkpoint_dir", str(self.checkpoint_dir),
                "--execution_id", execution_id
            ]

            # ç’°å¢ƒå¤‰æ•°è¨­å®š
            env = os.environ.copy()
            env['PYTHONPATH'] = f"{os.getcwd()};{os.getcwd()}/scripts;{os.getcwd()}/utils"

            # ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œ
            logger.info(f"Running command: {' '.join(cmd)}")
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                env=env,
                cwd=os.getcwd()
            )

            # å®Ÿè¡Œç›£è¦–
            stdout, stderr = process.communicate(timeout=3600)  # 1æ™‚é–“ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

            # çµæœç¢ºèª
            if process.returncode == 0:
                logger.info(f"âœ… Pipeline {execution_id} completed successfully")

                # æˆåŠŸæ™‚ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
                self._save_execution_checkpoint(execution_id, "success")

            else:
                logger.error(f"[ERROR] Pipeline {execution_id} failed with code {process.returncode}")
                logger.error(f"STDOUT: {stdout}")
                logger.error(f"STDERR: {stderr}")

                # å¤±æ•—æ™‚ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
                self._save_execution_checkpoint(execution_id, "failed")

        except subprocess.TimeoutExpired:
            logger.error(f"â° Pipeline {execution_id} timed out")
            process.kill()
        except Exception as e:
            logger.error(f"ğŸ’¥ Pipeline {execution_id} error: {e}")

    def _save_execution_checkpoint(self, execution_id: str, status: str):
        """å®Ÿè¡Œãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜"""
        try:
            checkpoint_data = {
                "execution_id": execution_id,
                "timestamp": datetime.now().isoformat(),
                "iteration": self.iteration_count,
                "status": status,
                "output_dir": str(self.output_dir / execution_id),
                "system_info": {
                    "cpu_percent": psutil.cpu_percent(),
                    "memory_percent": psutil.virtual_memory().percent,
                    "disk_usage": psutil.disk_usage('/').percent
                }
            }

            checkpoint_path = self.checkpoint_dir / f"execution_{execution_id}_{status}.json"

            import json
            with open(checkpoint_path, 'w', encoding='utf-8') as f:
                json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)

            logger.info(f"[INFO] Execution checkpoint saved: {checkpoint_path}")

        except Exception as e:
            logger.error(f"Failed to save execution checkpoint: {e}")

    def _check_system_ready(self) -> bool:
        """ã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿè¡Œæº–å‚™ãŒã§ãã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            # CPUä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯ (90%æœªæº€)
            cpu_percent = psutil.cpu_percent(interval=1)
            if cpu_percent > 90:
                logger.warning(f"High CPU usage: {cpu_percent}%")
                return False

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯ (90%æœªæº€)
            memory = psutil.virtual_memory()
            if memory.percent > 90:
                logger.warning(f"High memory usage: {memory.percent}%")
                return False

            # ãƒ‡ã‚£ã‚¹ã‚¯ç©ºãå®¹é‡ãƒã‚§ãƒƒã‚¯ (1GBä»¥ä¸Š)
            disk = psutil.disk_usage('/')
            if disk.free < 1 * 1024 * 1024 * 1024:  # 1GB
                logger.warning(f"Low disk space: {disk.free / (1024**3):.2f} GB")
                return False

            # GPUãƒã‚§ãƒƒã‚¯ (åˆ©ç”¨å¯èƒ½ãªå ´åˆ)
            try:
                import torch
                if torch.cuda.is_available():
                    gpu_memory = torch.cuda.get_device_properties(0).total_memory
                    gpu_used = torch.cuda.memory_allocated(0)
                    gpu_free = gpu_memory - gpu_used

                    if gpu_free < 2 * 1024 * 1024 * 1024:  # 2GB
                        logger.warning(f"Low GPU memory: {gpu_free / (1024**3):.2f} GB")
                        return False
            except:
                pass  # GPUãƒã‚§ãƒƒã‚¯å¤±æ•—ã¯ç„¡è¦–

            return True

        except Exception as e:
            logger.error(f"System check failed: {e}")
            return False

    def _wait_for_next_execution(self):
        """æ¬¡å›å®Ÿè¡Œã¾ã§å¾…æ©Ÿ"""
        wait_seconds = self.interval_minutes * 60

        logger.info(f"â³ Waiting {self.interval_minutes} minutes until next execution...")
        logger.info(f"Next execution at: {datetime.now() + timedelta(minutes=self.interval_minutes)}")

        # å¾…æ©Ÿï¼ˆã‚·ã‚°ãƒŠãƒ«ã§ä¸­æ–­å¯èƒ½ï¼‰
        for i in range(wait_seconds):
            if not self.running:
                break
            time.sleep(1)

    def _signal_handler(self, signum, frame):
        """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
        logger.info(f"Received signal {signum}")
        self.stop()

    def _cleanup(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†"""
        logger.info("Performing cleanup...")

        # å®Ÿè¡ŒçŠ¶æ…‹ã®ä¿å­˜
        final_status = {
            "total_iterations": self.iteration_count,
            "last_execution": self.last_execution_time.isoformat() if self.last_execution_time else None,
            "final_timestamp": datetime.now().isoformat(),
            "status": "completed" if self.running else "stopped"
        }

        status_path = self.output_dir / "pipeline_status.json"
        import json
        with open(status_path, 'w', encoding='utf-8') as f:
            json.dump(final_status, f, indent=2, ensure_ascii=False)

        logger.info(f"Final status saved to {status_path}")

def main():
    parser = argparse.ArgumentParser(description="SO8T Automatic Pipeline Runner")

    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š
    parser.add_argument("--pipeline-script",
                       default="scripts/training/train_borea_phi35_so8t_ppo.py",
                       help="Pipeline script to execute")
    parser.add_argument("--dataset-path",
                       default="data/so8t_quadruple_dataset.jsonl",
                       help="Dataset path")
    parser.add_argument("--output-dir",
                       default="outputs/so8t_auto_pipeline",
                       help="Output directory")
    parser.add_argument("--checkpoint-dir",
                       default="checkpoints/so8t_rolling",
                       help="Checkpoint directory")

    # å®Ÿè¡Œè¨­å®š
    parser.add_argument("--interval-minutes", type=int, default=3,
                       help="Execution interval in minutes")
    parser.add_argument("--max-checkpoints", type=int, default=5,
                       help="Maximum number of checkpoints to keep")
    parser.add_argument("--max-iterations", type=int, default=None,
                       help="Maximum number of iterations (None for infinite)")

    # ãƒ‡ãƒãƒƒã‚°è¨­å®š
    parser.add_argument("--dry-run", action="store_true",
                       help="Dry run mode (don't execute pipeline)")
    parser.add_argument("--single-run", action="store_true",
                       help="Single run mode (execute once and exit)")

    args = parser.parse_args()

    # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    Path("logs").mkdir(exist_ok=True)

    # è‡ªå‹•å®Ÿè¡Œã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
    runner = SO8TAutoPipelineRunner(
        pipeline_script=args.pipeline_script,
        dataset_path=args.dataset_path,
        output_dir=args.output_dir,
        checkpoint_dir=args.checkpoint_dir,
        interval_minutes=args.interval_minutes,
        max_checkpoints=args.max_checkpoints,
        max_iterations=1 if args.single_run else args.max_iterations
    )

    if args.dry_run:
        logger.info("=== DRY RUN MODE ===")
        logger.info("System check result:")
        ready = runner._check_system_ready()
        logger.info(f"System ready: {ready}")
        return

    # å®Ÿè¡Œé–‹å§‹
    try:
        runner.start()
    except KeyboardInterrupt:
        logger.info("Interrupted by user")
    except Exception as e:
        logger.error(f"Unexpected error: {e}")

if __name__ == "__main__":
    main()

