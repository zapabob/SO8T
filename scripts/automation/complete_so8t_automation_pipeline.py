#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Complete SO8T Automation Pipeline

Borea-Phi3.5-instinct-jpã®å®Œå…¨è‡ªå‹•SO8T/thinkingãƒ¢ãƒ‡ãƒ«åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼š
1. ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåé›†ï¼ˆNSFW/éŸ³å£°ãƒ‡ãƒ¼ã‚¿å«ã‚€ï¼‰
2. å››å€¤åˆ†é¡ã¨ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
3. PPOãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° with SO8ViTã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼
4. ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«çµ±åˆ
5. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã¨çµ±è¨ˆå‡¦ç†
6. HFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
7. ã‚¿ã‚¹ã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è‡ªå‹•å‰Šé™¤
"""

import os
import sys
import json
import logging
import argparse
import subprocess
import time
import threading
import queue
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
import traceback
from tqdm import tqdm

# SO8Té–¢é€£ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from so8t.core.dynamic_thinking_so8t import create_dynamic_thinking_so8t
    from so8t.optimization.bayesian_alpha_optimizer import create_bayesian_optimizer
    from so8t.evaluation.comprehensive_benchmark_evaluator import run_comprehensive_evaluation
except ImportError as e:
    logging.warning(f"SO8T import failed: {e}")

# ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(name)s - %(funcName)s:%(lineno)d - %(message)s',
    handlers=[
        logging.FileHandler(f'logs/complete_automation_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# tqdmè¨­å®š
tqdm.monitor_interval = 0  # å³æ™‚æ›´æ–°


class SO8TAutomationPipeline:
    """
    å®Œå…¨è‡ªå‹•SO8Tãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

    é›»æºæŠ•å…¥æ™‚è‡ªå‹•èµ·å‹•ã‹ã‚‰HFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†ã¾ã§
    """

    def __init__(self, config_path: str = "configs/complete_so8t_pipeline.yaml"):
        self.config_path = Path(config_path)
        self.config = self._load_config()
        self.pipeline_status = {}
        self.error_log = []

        # ãƒ‘ã‚¹è¨­å®š
        self.base_dir = Path("D:/webdataset")
        self.models_dir = self.base_dir / "models"
        self.checkpoints_dir = self.base_dir / "checkpoints" / "training"
        self.datasets_dir = self.base_dir / "datasets"
        self.gguf_dir = self.base_dir / "gguf_models"
        self.logs_dir = Path("logs")

        # tqdmè¨­å®š
        self.main_progress = None
        self.step_progress = None

        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚­ãƒ¥ãƒ¼
        self.debug_queue = queue.Queue()
        self.debug_thread = None
        self.debug_enabled = True

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        for dir_path in [self.models_dir, self.checkpoints_dir, self.datasets_dir,
                        self.gguf_dir, self.logs_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)

        # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        self._start_debug_output()

        logger.info("SO8T Automation Pipeline initialized with tqdm and debug output")
        logger.debug(f"Config loaded: {self.config_path}")
        logger.debug(f"Base directory: {self.base_dir}")
        logger.debug(f"Debug output: {'enabled' if self.debug_enabled else 'disabled'}")

    def _start_debug_output(self):
        """ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹"""
        if not self.debug_enabled:
            return

        def debug_worker():
            while self.debug_enabled:
                try:
                    # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å–å¾—ã—ã¦è¡¨ç¤º
                    debug_info = self.debug_queue.get(timeout=1.0)
                    if debug_info:
                        level, message = debug_info
                        if level == 'progress':
                            print(f"\r[DEBUG] {message}", end='', flush=True)
                        elif level == 'info':
                            print(f"\n[DEBUG] {message}")
                        elif level == 'warning':
                            print(f"\n[WARNING] {message}")
                        elif level == 'error':
                            print(f"\n[ERROR] {message}")
                except queue.Empty:
                    continue
                except Exception as e:
                    print(f"\n[DEBUG ERROR] {e}")

        self.debug_thread = threading.Thread(target=debug_worker, daemon=True)
        self.debug_thread.start()
        logger.debug("Debug output thread started")

    def _debug_print(self, message: str, level: str = 'info'):
        """ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ï¼ˆéåŒæœŸï¼‰"""
        if self.debug_enabled:
            self.debug_queue.put((level, message))

    def _update_progress(self, step_name: str, current: int, total: int, message: str = ""):
        """ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°"""
        if self.step_progress:
            self.step_progress.n = current
            self.step_progress.total = total
            if message:
                self.step_progress.set_description(f"[STEP {current}/{total}] {step_name}: {message}")
            else:
                self.step_progress.set_description(f"[STEP {current}/{total}] {step_name}")
            self.step_progress.refresh()

        self._debug_print(f"Progress: {step_name} {current}/{total} - {message}", 'progress')

    def _load_config(self) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        import yaml

        default_config = {
            'model': {
                'base_model': 'microsoft/phi-3.5-mini-instruct',
                'target_model': 'Borea-Phi3.5-instinct-jp',
                'output_name': 'borea_phi35_so8t_multimodal'
            },
            'data': {
                'multimodal_datasets': [
                    'HuggingFaceFW/fineweb-2',  # ãƒ†ã‚­ã‚¹ãƒˆ
                    'laion/aesthetic-predictor-5',  # ç”»åƒè©•ä¾¡
                    'mozilla-foundation/common_voice_11_0',  # éŸ³å£°
                    'deepghs/nsfw_detect',  # NSFWæ¤œçŸ¥
                ],
                'license_filter': ['mit', 'apache-2.0'],
                'max_samples_per_dataset': 50000,
                'test_split_ratio': 0.2
            },
            'training': {
                'ppo_epochs': 3,
                'batch_size': 4,
                'learning_rate': 1e-5,
                'max_steps': 1000,
                'so8vit_enabled': True,
                'multimodal_enabled': True,
                'bayesian_optimization': True
            },
            'benchmark': {
                'datasets': ['elyza_100', 'mmlu', 'gsm8k', 'hellaswag'],
                'significance_level': 0.05,
                'performance_threshold': 0.75
            },
            'automation': {
                'auto_resume_on_power_on': True,
                'error_retry_count': 3,
                'cleanup_on_success': True
            }
        }

        if self.config_path.exists():
            with open(self.config_path, 'r', encoding='utf-8') as f:
                user_config = yaml.safe_load(f)
            default_config.update(user_config)

        return default_config

    def run_complete_pipeline(self) -> bool:
        """
        å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ with tqdm and debug output

        Returns:
            æˆåŠŸ/å¤±æ•—
        """
        logger.info("="*80)
        logger.info("STARTING COMPLETE SO8T AUTOMATION PIPELINE")
        logger.info("="*80)
        logger.debug("Initializing main progress bar...")

        # ãƒ¡ã‚¤ãƒ³ã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼åˆæœŸåŒ–
        self.main_progress = tqdm(
            total=7,
            desc="[PIPELINE] Complete SO8T Automation",
            unit="step",
            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] {desc}',
            position=0,
            leave=True
        )

        self._debug_print("Pipeline started - 7 steps total", 'info')

        try:
            # STEP 1: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåé›†
            self.main_progress.set_description("[PIPELINE] Step 1/7: Multimodal Data Collection")
            self._debug_print("Starting Step 1: Multimodal Data Collection", 'info')
            if not self._step_multimodal_data_collection():
                raise RuntimeError("Data collection failed")
            self.main_progress.update(1)
            self._debug_print("Completed Step 1: Data collection successful", 'info')

            # STEP 2: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ï¼ˆå››å€¤åˆ†é¡ + ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ï¼‰
            self.main_progress.set_description("[PIPELINE] Step 2/7: Data Preprocessing")
            self._debug_print("Starting Step 2: Data Preprocessing", 'info')
            if not self._step_data_preprocessing():
                raise RuntimeError("Data preprocessing failed")
            self.main_progress.update(1)
            self._debug_print("Completed Step 2: Data preprocessing successful", 'info')

            # STEP 3: PPOãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° with SO8ViT + ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«
            self.main_progress.set_description("[PIPELINE] Step 3/7: PPO Training")
            self._debug_print("Starting Step 3: PPO Training with SO8ViT", 'info')
            if not self._step_ppo_training():
                raise RuntimeError("PPO training failed")
            self.main_progress.update(1)
            self._debug_print("Completed Step 3: PPO training successful", 'info')

            # STEP 4: ãƒ¢ãƒ‡ãƒ«çµ±åˆã¨æœ€é©åŒ–
            self.main_progress.set_description("[PIPELINE] Step 4/7: Model Integration")
            self._debug_print("Starting Step 4: Model Integration", 'info')
            if not self._step_model_integration():
                raise RuntimeError("Model integration failed")
            self.main_progress.update(1)
            self._debug_print("Completed Step 4: Model integration successful", 'info')

            # STEP 5: åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡
            self.main_progress.set_description("[PIPELINE] Step 5/7: Benchmark Evaluation")
            self._debug_print("Starting Step 5: Benchmark Evaluation", 'info')
            if not self._step_comprehensive_benchmark():
                raise RuntimeError("Benchmark evaluation failed")
            self.main_progress.update(1)
            self._debug_print("Completed Step 5: Benchmark evaluation successful", 'info')

            # STEP 6: HFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            self.main_progress.set_description("[PIPELINE] Step 6/7: HF Upload")
            self._debug_print("Starting Step 6: HuggingFace Upload", 'info')
            if not self._step_huggingface_upload():
                raise RuntimeError("HuggingFace upload failed")
            self.main_progress.update(1)
            self._debug_print("Completed Step 6: HF upload successful", 'info')

            # STEP 7: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨ã‚¿ã‚¹ã‚¯å‰Šé™¤
            self.main_progress.set_description("[PIPELINE] Step 7/7: Cleanup")
            self._debug_print("Starting Step 7: Cleanup and Task Removal", 'info')
            if not self._step_cleanup_and_task_removal():
                logger.warning("Cleanup failed, but pipeline completed")
            self.main_progress.update(1)
            self._debug_print("Completed Step 7: Cleanup successful", 'info')

            logger.info("="*80)
            logger.info("COMPLETE SO8T AUTOMATION PIPELINE SUCCESS!")
            logger.info("="*80)

            return True

        except Exception as e:
            logger.error(f"Pipeline failed: {e}")
            logger.error(traceback.format_exc())
            self._handle_pipeline_error(e)
            return False

        finally:
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.main_progress:
                self.main_progress.close()
            if self.step_progress:
                self.step_progress.close()
            self.debug_enabled = False
            self._debug_print("Pipeline execution finished", 'info')
            logger.info("Pipeline cleanup completed")

    def __del__(self):
        """ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ - ãƒ‡ãƒãƒƒã‚°ã‚¹ãƒ¬ãƒƒãƒ‰ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.debug_enabled = False
        logger.debug("SO8TAutomationPipeline destructor called")

    def _step_multimodal_data_collection(self) -> bool:
        """STEP 1: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåé›† with tqdm and debug"""
        logger.info("STEP 1: Multimodal Data Collection")
        logger.info("-" * 50)
        self._debug_print("Initializing multimodal data collection sub-steps", 'info')

        # ã‚µãƒ–ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä½œæˆ
        sub_steps = 4  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰, çµ±åˆ, æ¤œè¨¼, çµ±è¨ˆ
        self.step_progress = tqdm(
            total=sub_steps,
            desc="[STEP 1] Data Collection",
            unit="substep",
            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {desc}',
            position=1,
            leave=False
        )

        try:
            self._update_progress("Data Collection", 0, sub_steps, "Initializing")
            # HFãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
            self._update_progress("Data Collection", 1, sub_steps, "Downloading datasets")
            self._debug_print("Starting HF dataset download...", 'info')
            cmd = [
                sys.executable, "scripts/data/expand_datasets.py",
                "--output", str(self.datasets_dir / "multimodal_raw"),
                "--datasets", json.dumps(self.config['data']['multimodal_datasets']),
                "--licenses", json.dumps(self.config['data']['license_filter']),
                "--max-samples", str(self.config['data']['max_samples_per_dataset'])
            ]

            logger.debug(f"Running command: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
            if result.returncode != 0:
                logger.error(f"Data collection failed: {result.stderr}")
                self._debug_print(f"Data collection error: {result.stderr}", 'error')
                return False
            self._debug_print("Dataset download completed successfully", 'info')

            # NSFWãƒ‡ãƒ¼ã‚¿è¿½åŠ 
            self._update_progress("Data Collection", 2, sub_steps, "Collecting NSFW data")
            self._debug_print("Collecting NSFW datasets...", 'info')
            if not self._collect_nsfw_data():
                logger.warning("NSFW data collection failed, continuing...")
                self._debug_print("NSFW data collection failed, continuing", 'warning')

            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
            self._update_progress("Data Collection", 3, sub_steps, "Collecting audio data")
            self._debug_print("Collecting audio datasets...", 'info')
            if not self._collect_audio_data():
                logger.warning("Audio data collection failed, continuing...")
                self._debug_print("Audio data collection failed, continuing", 'warning')

            # ãƒ‡ãƒ¼ã‚¿çµ±åˆã¨æ¤œè¨¼
            self._update_progress("Data Collection", 4, sub_steps, "Integrating and validating")
            self._debug_print("Integrating collected datasets...", 'info')
            if not self._integrate_collected_datasets():
                logger.error("Dataset integration failed")
                self._debug_print("Dataset integration failed", 'error')
                return False

            self.step_progress.close()
            self.pipeline_status['data_collection'] = 'completed'
            logger.info("âœ“ Multimodal data collection completed")
            self._debug_print("Data collection step completed successfully", 'info')
            return True

        except Exception as e:
            logger.error(f"Data collection error: {e}")
            self.error_log.append({'step': 'data_collection', 'error': str(e)})
            return False

    def _collect_nsfw_data(self) -> bool:
        """NSFWãƒ‡ãƒ¼ã‚¿åé›†"""
        try:
            cmd = [
                sys.executable, "scripts/data/expand_datasets.py",
                "--output", str(self.datasets_dir / "nsfw_data"),
                "--datasets", '["deepghs/nsfw_detect", "FredZhang7/anime-kawaii-diffusion"]',
                "--max-samples", "10000"
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
            return result.returncode == 0
        except Exception as e:
            return False

    def _collect_audio_data(self) -> bool:
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿åé›†"""
        try:
            cmd = [
                sys.executable, "scripts/data/expand_datasets.py",
                "--output", str(self.datasets_dir / "audio_data"),
                "--datasets", '["mozilla-foundation/common_voice_11_0"]',
                "--max-samples", "5000"
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
            return result.returncode == 0
        except Exception as e:
            return False

    def _step_data_preprocessing(self) -> bool:
        """STEP 2: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ï¼ˆå››å€¤åˆ†é¡ + ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ï¼‰ with tqdm and debug"""
        logger.info("STEP 2: Data Preprocessing")
        logger.info("-" * 50)
        self._debug_print("Initializing data preprocessing sub-steps", 'info')

        # ã‚µãƒ–ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä½œæˆ
        sub_steps = 4  # å››å€¤åˆ†é¡, ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°, çµ±è¨ˆåˆ†æ, æ¤œè¨¼
        self.step_progress = tqdm(
            total=sub_steps,
            desc="[STEP 2] Data Preprocessing",
            unit="substep",
            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {desc}',
            position=1,
            leave=False
        )

        try:
            self._update_progress("Data Preprocessing", 0, sub_steps, "Initializing")
            # å››å€¤åˆ†é¡å®Ÿè¡Œ
            self._update_progress("Data Preprocessing", 1, sub_steps, "Four-class labeling")
            self._debug_print("Starting four-class labeling...", 'info')
            cmd = [
                sys.executable, "scripts/data/label_four_class_dataset_fixed.py",
                "--input", str(self.datasets_dir / "multimodal_raw"),
                "--output", str(self.datasets_dir / "labeled_data"),
                "--multimodal", "true"
            ]

            logger.debug(f"Running command: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
            if result.returncode != 0:
                logger.error(f"Four-class labeling failed: {result.stderr}")
                self._debug_print(f"Four-class labeling error: {result.stderr}", 'error')
                return False
            self._debug_print("Four-class labeling completed successfully", 'info')

            # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
            self._update_progress("Data Preprocessing", 2, sub_steps, "Data cleansing")
            self._debug_print("Starting data cleansing...", 'info')
            cmd = [
                sys.executable, "scripts/data/cleanse_codex_pairwise_dataset.py",
                "--input", str(self.datasets_dir / "labeled_data"),
                "--output", str(self.datasets_dir / "cleansed_data"),
                "--multimodal", "true"
            ]

            logger.debug(f"Running command: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
            if result.returncode != 0:
                logger.error(f"Data cleansing failed: {result.stderr}")
                self._debug_print(f"Data cleansing error: {result.stderr}", 'error')
                return False
            self._debug_print("Data cleansing completed successfully", 'info')

            # scikit-learnã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
            self._update_progress("Data Preprocessing", 3, sub_steps, "Data splitting")
            self._debug_print("Starting data splitting with scikit-learn...", 'info')
            cmd = [
                sys.executable, "scripts/data/label_four_class_dataset_fixed.py",
                "--input", str(self.datasets_dir / "cleansed_data"),
                "--output", str(self.datasets_dir / "final_dataset"),
                "--split", "true",
                "--test-ratio", str(self.config['data']['test_split_ratio'])
            ]

            logger.debug(f"Running command: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
            if result.returncode != 0:
                logger.error(f"Data splitting failed: {result.stderr}")
                self._debug_print(f"Data splitting error: {result.stderr}", 'error')
                return False
            self._debug_print("Data splitting completed successfully", 'info')

            # çµ±è¨ˆåˆ†æã¨æ¤œè¨¼
            self._update_progress("Data Preprocessing", 4, sub_steps, "Validation")
            self._debug_print("Performing final validation...", 'info')
            if not self._validate_preprocessed_data():
                logger.error("Data validation failed")
                self._debug_print("Data validation failed", 'error')
                return False

            self.step_progress.close()
            self.pipeline_status['data_preprocessing'] = 'completed'
            logger.info("âœ“ Data preprocessing completed")
            self._debug_print("Data preprocessing step completed successfully", 'info')
            return True

        except Exception as e:
            logger.error(f"Data preprocessing error: {e}")
            self.error_log.append({'step': 'data_preprocessing', 'error': str(e)})
            return False

    def _step_ppo_training(self) -> bool:
        """STEP 3: PPOãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° with SO8ViT + ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« with tqdm and debug"""
        logger.info("STEP 3: PPO Training with SO8ViT + Multimodal")
        logger.info("-" * 50)
        self._debug_print("Initializing PPO training sub-steps", 'info')

        # ã‚µãƒ–ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä½œæˆ
        sub_steps = 3  # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ, ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ¤œè¨¼, çµæœç¢ºèª
        self.step_progress = tqdm(
            total=sub_steps,
            desc="[STEP 3] PPO Training",
            unit="substep",
            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {desc}',
            position=1,
            leave=False
        )

        try:
            self._update_progress("PPO Training", 0, sub_steps, "Initializing")
            # é«˜åº¦ãªPhi-3.5 SO8Tãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
            self._update_progress("PPO Training", 1, sub_steps, "Running training")
            self._debug_print("Starting advanced Phi-3.5 SO8T training...", 'info')
            cmd = [
                sys.executable, "scripts/training/train_phi35_advanced_pipeline.py",
                "--config", "configs/train_phi35_so8t_annealing.yaml",
                "--output", str(self.checkpoints_dir / f"phi35_so8t_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
            ]

            logger.debug(f"Running command: {' '.join(cmd)}")
            # PPOãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯æ™‚é–“ãŒã‹ã‹ã‚‹ã®ã§ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡ºåŠ›ã‚’è¡¨ç¤º
            self._debug_print("Training may take several hours - monitor logs for progress", 'warning')
            result = subprocess.run(cmd, capture_output=False, text=True, cwd=os.getcwd())
            if result.returncode != 0:
                logger.error(f"PPO training failed: {result.stderr}")
                self._debug_print(f"PPO training error: {result.stderr}", 'error')
                return False
            self._debug_print("PPO training completed successfully", 'info')

            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ¤œè¨¼
            self._update_progress("PPO Training", 2, sub_steps, "Validating checkpoints")
            self._debug_print("Validating training checkpoints...", 'info')
            if not self._validate_training_checkpoints():
                logger.error("Checkpoint validation failed")
                self._debug_print("Checkpoint validation failed", 'error')
                return False

            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµæœç¢ºèª
            self._update_progress("PPO Training", 3, sub_steps, "Checking results")
            self._debug_print("Checking training results...", 'info')
            if not self._check_training_results():
                logger.error("Training results check failed")
                self._debug_print("Training results check failed", 'error')
                return False

            self.step_progress.close()
            self.pipeline_status['ppo_training'] = 'completed'
            logger.info("âœ“ PPO training completed")
            self._debug_print("PPO training step completed successfully", 'info')
            return True

        except Exception as e:
            logger.error(f"PPO training error: {e}")
            self.error_log.append({'step': 'ppo_training', 'error': str(e)})
            return False

    def _step_model_integration(self) -> bool:
        """STEP 4: ãƒ¢ãƒ‡ãƒ«çµ±åˆã¨æœ€é©åŒ–"""
        logger.info("STEP 4: Model Integration and Optimization")
        logger.info("-" * 50)

        try:
            # SO8TåŠ¹æœã®ç„¼ãè¾¼ã¿
            cmd = [
                "python", "scripts/conversion/bake_and_convert_to_gguf.bat"
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
            if result.returncode != 0:
                logger.error(f"Model integration failed: {result.stderr}")
                return False

            # ç„¼ãè¾¼ã¿æ¤œè¨¼
            cmd = [
                sys.executable, "scripts/conversion/verify_so8t_baking.py",
                "--original", str(self.checkpoints_dir / "phi35_advanced_*" / "final_model"),
                "--baked", str(self.models_dir / "baked_for_gguf" / "phi35_so8t_baked")
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
            if result.returncode != 0:
                logger.warning(f"Baking verification failed: {result.stderr}")

            self.pipeline_status['model_integration'] = 'completed'
            logger.info("âœ“ Model integration completed")
            return True

        except Exception as e:
            logger.error(f"Model integration error: {e}")
            self.error_log.append({'step': 'model_integration', 'error': str(e)})
            return False

    def _step_comprehensive_benchmark(self) -> bool:
        """STEP 5: åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡"""
        logger.info("STEP 5: Comprehensive Benchmark Evaluation")
        logger.info("-" * 50)

        try:
            # åŒ…æ‹¬çš„è©•ä¾¡å®Ÿè¡Œ
            evaluation_result = run_comprehensive_evaluation(
                model_a_path=self.config['model']['base_model'],
                model_b_path=str(self.models_dir / "baked_for_gguf" / "phi35_so8t_baked"),
                output_dir=str(self.base_dir / "evaluation_results" / f"so8t_pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
            )

            # æ€§èƒ½ãƒã‚§ãƒƒã‚¯
            conclusion = evaluation_result.get('conclusion', {})
            if conclusion.get('statistically_significant') and conclusion.get('performance_difference', 0) > 0:
                logger.info(f"âœ“ Model performance improved: +{conclusion['performance_difference']:.3f}")
            else:
                logger.warning(f"âš  Model performance not significantly improved: {conclusion.get('performance_difference', 0):.3f}")

            self.pipeline_status['benchmark'] = 'completed'
            logger.info("âœ“ Benchmark evaluation completed")
            return True

        except Exception as e:
            logger.error(f"Benchmark evaluation error: {e}")
            self.error_log.append({'step': 'benchmark', 'error': str(e)})
            return False

    def _step_huggingface_upload(self) -> bool:
        """STEP 6: HFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        logger.info("STEP 6: HuggingFace Upload")
        logger.info("-" * 50)

        try:
            # HFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
            cmd = [
                sys.executable, "scripts/upload_aegis_to_huggingface.py",
                "--model", str(self.models_dir / "baked_for_gguf" / "phi35_so8t_baked"),
                "--gguf", str(self.gguf_dir / "phi35_so8t_baked"),
                "--name", self.config['model']['output_name'],
                "--type", "so8t_multimodal"
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
            if result.returncode != 0:
                logger.error(f"HF upload failed: {result.stderr}")
                return False

            self.pipeline_status['hf_upload'] = 'completed'
            logger.info("âœ“ HuggingFace upload completed")
            return True

        except Exception as e:
            logger.error(f"HF upload error: {e}")
            self.error_log.append({'step': 'hf_upload', 'error': str(e)})
            return False

    def _step_cleanup_and_task_removal(self) -> bool:
        """STEP 7: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨ã‚¿ã‚¹ã‚¯å‰Šé™¤"""
        logger.info("STEP 7: Cleanup and Task Removal")
        logger.info("-" * 50)

        try:
            # PowerShellã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã‚¿ã‚¹ã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‰Šé™¤
            ps_script = f'''
            $taskName = "SO8T_Automation_Pipeline"
            try {{
                Unregister-ScheduledTask -TaskName $taskName -Confirm:$false -ErrorAction Stop
                Write-Host "Successfully removed scheduled task: $taskName"
            }} catch {{
                Write-Host "Task removal failed or task not found: $($_.Exception.Message)"
            }}
            '''

            with open('temp_task_removal.ps1', 'w') as f:
                f.write(ps_script)

            result = subprocess.run([
                "powershell", "-ExecutionPolicy", "Bypass", "-File", "temp_task_removal.ps1"
            ], capture_output=True, text=True)

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            Path('temp_task_removal.ps1').unlink(missing_ok=True)

            if result.returncode == 0:
                logger.info("âœ“ Scheduled task removed successfully")
            else:
                logger.warning(f"Task removal warning: {result.stderr}")

            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†ãƒ­ã‚°
            completion_log = {
                'pipeline_completed_at': str(datetime.now()),
                'total_steps': 7,
                'completed_steps': len([s for s in self.pipeline_status.values() if s == 'completed']),
                'errors': self.error_log,
                'final_model_path': str(self.models_dir / "baked_for_gguf" / "phi35_so8t_baked"),
                'gguf_model_path': str(self.gguf_dir / self.config['model']['output_name']),
                'hf_model_name': self.config['model']['output_name']
            }

            with open(self.logs_dir / f"pipeline_completion_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", 'w') as f:
                json.dump(completion_log, f, indent=2, default=str)

            self.pipeline_status['cleanup'] = 'completed'
            logger.info("âœ“ Cleanup and task removal completed")
            return True

        except Exception as e:
            logger.error(f"Cleanup error: {e}")
            self.error_log.append({'step': 'cleanup', 'error': str(e)})
            return False

    def _integrate_collected_datasets(self) -> bool:
        """åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±åˆ"""
        try:
            self._debug_print("Integrating multimodal datasets...", 'info')
            # æ—¢å­˜ã®çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½¿ç”¨
            cmd = [
                sys.executable, "scripts/data/integrate_hf_datasets.py",
                "--input", str(self.datasets_dir / "multimodal_raw"),
                "--output", str(self.datasets_dir / "integrated_multimodal.jsonl")
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
            if result.returncode != 0:
                logger.warning(f"Dataset integration warning: {result.stderr}")
                return False
            return True
        except Exception as e:
            logger.error(f"Dataset integration error: {e}")
            return False

    def _validate_preprocessed_data(self) -> bool:
        """å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
        try:
            output_file = self.datasets_dir / "final_dataset" / "train.jsonl"
            if not output_file.exists():
                logger.error(f"Training data file not found: {output_file}")
                return False

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            size_mb = output_file.stat().st_size / (1024 * 1024)
            if size_mb < 10:
                logger.warning(f"Training data size is small: {size_mb:.1f} MB")
                self._debug_print(f"Warning: Small training dataset ({size_mb:.1f} MB)", 'warning')

            # ã‚µãƒ³ãƒ—ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
            sample_count = 0
            with open(output_file, 'r', encoding='utf-8') as f:
                for line in f:
                    sample_count += 1
                    if sample_count >= 100:  # æœ€åˆã®100è¡Œã ã‘ã‚«ã‚¦ãƒ³ãƒˆ
                        break

            if sample_count < 50:
                logger.error(f"Insufficient training samples: {sample_count}")
                return False

            self._debug_print(f"Data validation passed: {sample_count}+ samples, {size_mb:.1f} MB", 'info')
            return True
        except Exception as e:
            logger.error(f"Data validation error: {e}")
            return False

    def _validate_training_checkpoints(self) -> bool:
        """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®æ¤œè¨¼"""
        try:
            checkpoint_dir = self.checkpoints_dir / f"phi35_so8t_{datetime.now().strftime('%Y%m%d')}"
            if not checkpoint_dir.exists():
                # æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ã™
                checkpoint_dirs = list(self.checkpoints_dir.glob("phi35_so8t_*"))
                if not checkpoint_dirs:
                    logger.error("No checkpoint directory found")
                    return False
                checkpoint_dir = max(checkpoint_dirs, key=lambda x: x.stat().st_mtime)

            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            checkpoint_files = list(checkpoint_dir.glob("*.pt"))
            if not checkpoint_files:
                logger.error(f"No checkpoint files found in {checkpoint_dir}")
                return False

            # æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            latest_checkpoint = max(checkpoint_files, key=lambda x: x.stat().st_mtime)
            size_gb = latest_checkpoint.stat().st_size / (1024**3)

            if size_gb < 1.0:
                logger.warning(f"Checkpoint file seems small: {size_gb:.2f} GB")
                self._debug_print(f"Warning: Small checkpoint file ({size_gb:.2f} GB)", 'warning')

            self._debug_print(f"Checkpoint validation passed: {len(checkpoint_files)} files, latest {size_gb:.2f} GB", 'info')
            return True
        except Exception as e:
            logger.error(f"Checkpoint validation error: {e}")
            return False

    def _check_training_results(self) -> bool:
        """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã®ç¢ºèª"""
        try:
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’ãƒã‚§ãƒƒã‚¯
            log_files = list(Path("logs").glob("complete_automation_*.log"))
            if not log_files:
                logger.warning("No training log files found")
                return True  # ãƒ­ã‚°ãŒãªãã¦ã‚‚æˆåŠŸã¨ã¿ãªã™

            latest_log = max(log_files, key=lambda x: x.stat().st_mtime)

            # ãƒ­ã‚°ã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ã‚’ç¢ºèª
            with open(latest_log, 'r', encoding='utf-8') as f:
                content = f.read()
                if "âœ“ PPO training completed" in content:
                    self._debug_print("Training completion confirmed in logs", 'info')
                    return True
                else:
                    logger.warning("Training completion not found in logs")
                    return False
        except Exception as e:
            logger.error(f"Training results check error: {e}")
            return False

    def _handle_pipeline_error(self, error: Exception):
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼å‡¦ç†"""
        logger.error(f"Pipeline error detected: {error}")

        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ä¿å­˜
        error_info = {
            'error_time': str(datetime.now()),
            'error_type': type(error).__name__,
            'error_message': str(error),
            'traceback': traceback.format_exc(),
            'pipeline_status': self.pipeline_status,
            'completed_steps': [k for k, v in self.pipeline_status.items() if v == 'completed'],
            'failed_step': self._identify_failed_step()
        }

        error_file = self.logs_dir / f"pipeline_error_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(error_file, 'w') as f:
            json.dump(error_info, f, indent=2, default=str)

        logger.error(f"Error details saved to: {error_file}")

        # ã‚¨ãƒ©ãƒ¼é€šçŸ¥ï¼ˆã‚ªãƒ¼ãƒ‡ã‚£ã‚ªï¼‰
        try:
            subprocess.run([
                "powershell", "-ExecutionPolicy", "Bypass",
                "-File", "scripts/utils/play_audio_notification.ps1"
            ], check=True)
        except:
            pass

    def _identify_failed_step(self) -> str:
        """å¤±æ•—ã—ãŸã‚¹ãƒ†ãƒƒãƒ—ã®ç‰¹å®š"""
        step_order = ['data_collection', 'data_preprocessing', 'ppo_training',
                     'model_integration', 'benchmark', 'hf_upload', 'cleanup']

        for step in step_order:
            if step not in self.pipeline_status or self.pipeline_status[step] != 'completed':
                return step
        return 'unknown'

    def get_pipeline_status(self) -> Dict[str, Any]:
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çŠ¶æ…‹å–å¾—"""
        return {
            'status': self.pipeline_status,
            'errors': self.error_log,
            'is_completed': all(v == 'completed' for v in self.pipeline_status.values()),
            'completion_percentage': len([v for v in self.pipeline_status.values() if v == 'completed']) / 7 * 100
        }


def create_power_on_task():
    """é›»æºæŠ•å…¥æ™‚è‡ªå‹•èµ·å‹•ã‚¿ã‚¹ã‚¯ä½œæˆ"""
    ps_script = '''
    $taskName = "SO8T_Automation_Pipeline"
    $scriptPath = "C:\\Users\\downl\\Desktop\\SO8T\\scripts\\automation\\run_complete_pipeline.bat"

    try {
        # æ—¢å­˜ã‚¿ã‚¹ã‚¯å‰Šé™¤ï¼ˆå¿µã®ãŸã‚ï¼‰
        Unregister-ScheduledTask -TaskName $taskName -Confirm:$false -ErrorAction SilentlyContinue

        # æ–°ã—ã„ã‚¿ã‚¹ã‚¯ä½œæˆ
        $action = New-ScheduledTaskAction -Execute "cmd.exe" -Argument "/c $scriptPath"
        $trigger = New-ScheduledTaskTrigger -AtLogOn
        $principal = New-ScheduledTaskPrincipal -UserId $env:USERNAME -LogonType InteractiveToken
        $settings = New-ScheduledTaskSettingsSet -AllowStartIfOnBatteries -DontStopIfGoingOnBatteries -StartWhenAvailable

        Register-ScheduledTask -TaskName $taskName -Action $action -Trigger $trigger -Principal $principal -Settings $settings -Description "SO8T Complete Automation Pipeline"

        Write-Host "Scheduled task created: $taskName"
    } catch {
        Write-Host "Failed to create scheduled task: $($_.Exception.Message)"
        exit 1
    }
    '''

    with open('create_power_on_task.ps1', 'w') as f:
        f.write(ps_script)

    result = subprocess.run([
        "powershell", "-ExecutionPolicy", "Bypass", "-File", "create_power_on_task.ps1"
    ], capture_output=True, text=True)

    Path('create_power_on_task.ps1').unlink(missing_ok=True)

    return result.returncode == 0


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description="Complete SO8T Automation Pipeline")
    parser.add_argument("--config", type=str, default="configs/complete_so8t_pipeline.yaml",
                       help="Configuration file")
    parser.add_argument("--create-task", action="store_true",
                       help="Create power-on scheduled task instead of running pipeline")
    parser.add_argument("--status", action="store_true",
                       help="Show current pipeline status")

    args = parser.parse_args()

    if args.create_task:
        # é›»æºæŠ•å…¥æ™‚ã‚¿ã‚¹ã‚¯ä½œæˆ
        logger.info("Creating power-on scheduled task...")
        if create_power_on_task():
            logger.info("âœ“ Power-on task created successfully")
        else:
            logger.error("âœ— Failed to create power-on task")
        return

    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    pipeline = SO8TAutomationPipeline(args.config)

    if args.status:
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
        status = pipeline.get_pipeline_status()
        print(json.dumps(status, indent=2, default=str))
        return

    # å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    success = pipeline.run_complete_pipeline()

    if success:
        logger.info("ğŸ‰ COMPLETE SO8T AUTOMATION PIPELINE FINISHED SUCCESSFULLY!")
        print("\nğŸ‰ Pipeline completed successfully!")
        print("Borea-Phi3.5-instinct-jp has been transformed into a complete SO8T/thinking multimodal model!")
        print("Model uploaded to HuggingFace and scheduled task removed.")
    else:
        logger.error("âŒ COMPLETE SO8T AUTOMATION PIPELINE FAILED!")
        print("\nâŒ Pipeline failed! Check logs for details.")
        sys.exit(1)


if __name__ == "__main__":
    main()
