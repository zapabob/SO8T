#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SO8Tçµ±åˆ¶Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é›†ä¸­ç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

Streamlitã‚’ä½¿ç”¨ã—ã¦ã€é€²è¡ŒçŠ¶æ³ã¨å„ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é›†ä¸­ç®¡ç†ã™ã‚‹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

Usage:
    streamlit run scripts/dashboard/so8t_scraping_dashboard.py
"""

import sys
import json
import time
import asyncio
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import pandas as pd
from PIL import Image

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False
    print("[ERROR] Streamlit not installed. Install with: pip install streamlit")
    sys.exit(1)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ScrapingDashboard:
    """SO8Tçµ±åˆ¶Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.output_dir = Path("D:/webdataset/processed")
        self.log_dir = Path("logs")
        self.checkpoint_dir = Path("D:/webdataset/checkpoints/pipeline")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
        if 'last_update' not in st.session_state:
            st.session_state.last_update = datetime.now()
        if 'scraping_stats' not in st.session_state:
            st.session_state.scraping_stats = {
                'total_samples': 0,
                'nsfw_samples': 0,
                'processed_keywords': 0,
                'total_keywords': 0,
                'browser_status': {}
            }
    
    def load_dashboard_state(self) -> Optional[Dict]:
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã¿"""
        state_file = self.output_dir / "dashboard_state.json"
        
        if state_file.exists():
            try:
                with open(state_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"Failed to load dashboard state: {e}")
        
        return None
    
    def load_latest_samples(self) -> List[Dict]:
        """æœ€æ–°ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        samples = []
        if self.output_dir.exists():
            # æœ€æ–°ã®JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
            jsonl_files = sorted(
                self.output_dir.glob("parallel_deep_research_scraped_*.jsonl"),
                key=lambda x: x.stat().st_mtime,
                reverse=True
            )
            
            if jsonl_files:
                latest_file = jsonl_files[0]
                try:
                    with open(latest_file, 'r', encoding='utf-8') as f:
                        for line in f:
                            if line.strip():
                                samples.append(json.loads(line))
                except Exception as e:
                    logger.error(f"Failed to load samples: {e}")
        
        return samples
    
    def load_log_data(self) -> List[str]:
        """ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        log_lines = []
        log_file = self.log_dir / "parallel_deep_research_scraping.log"
        
        if log_file.exists():
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    # æœ€å¾Œã®1000è¡Œã‚’èª­ã¿è¾¼ã¿
                    lines = f.readlines()
                    log_lines = lines[-1000:] if len(lines) > 1000 else lines
            except Exception as e:
                logger.error(f"Failed to load log: {e}")
        
        return log_lines
    
    def parse_browser_status_from_logs(self, log_lines: List[str]) -> Dict[int, Dict]:
        """ãƒ­ã‚°ã‹ã‚‰ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹ã‚’è§£æ"""
        browser_status = {}
        
        for line in log_lines:
            if "[BROWSER" in line and "]" in line:
                # ãƒ–ãƒ©ã‚¦ã‚¶ç•ªå·ã‚’æŠ½å‡º
                try:
                    browser_num = int(line.split("[BROWSER")[1].split("]")[0].strip())
                    
                    if browser_num not in browser_status:
                        browser_status[browser_num] = {
                            'status': 'active',
                            'current_keyword': None,
                            'samples_collected': 0,
                            'last_activity': None
                        }
                    
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‡¦ç†ä¸­
                    if "Processing keyword:" in line:
                        keyword = line.split("Processing keyword:")[1].strip()
                        browser_status[browser_num]['current_keyword'] = keyword
                        browser_status[browser_num]['last_activity'] = datetime.now().isoformat()
                    
                    # ã‚µãƒ³ãƒ—ãƒ«åé›†
                    if "Collected" in line and "samples" in line:
                        try:
                            count = int(line.split("Collected")[1].split("samples")[0].strip())
                            browser_status[browser_num]['samples_collected'] += count
                        except:
                            pass
                    
                    # å®Œäº†
                    if "finished" in line.lower() or "completed" in line.lower():
                        browser_status[browser_num]['status'] = 'completed'
                    
                except Exception:
                    continue
        
        return browser_status
    
    def parse_so8t_decisions_from_logs(self, log_lines: List[str]) -> List[Dict]:
        """ãƒ­ã‚°ã‹ã‚‰SO8Tåˆ¤æ–­çµæœã‚’è§£æ"""
        decisions = []
        
        for line in log_lines:
            if "[SO8T]" in line:
                decision = {
                    'timestamp': datetime.now().isoformat(),
                    'type': 'unknown',
                    'decision': 'unknown',
                    'reasoning': ''
                }
                
                if "Search denied" in line or "Search modified" in line:
                    decision['type'] = 'search'
                    decision['decision'] = 'denied' if "denied" in line else 'modified'
                elif "Scraping denied" in line or "Scraping modified" in line:
                    decision['type'] = 'scrape'
                    decision['decision'] = 'denied' if "denied" in line else 'modified'
                elif "Bypass denied" in line or "Bypass modified" in line:
                    decision['type'] = 'bypass'
                    decision['decision'] = 'denied' if "denied" in line else 'modified'
                
                if "Reasoning:" in line:
                    decision['reasoning'] = line.split("Reasoning:")[1].strip()
                
                decisions.append(decision)
        
        return decisions[-50:]  # æœ€å¾Œã®50ä»¶
    
    def load_browser_screenshots(self, screenshots_dir: Path, browser_status: Dict[int, Dict]) -> List[tuple]:
        """ãƒ–ãƒ©ã‚¦ã‚¶ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿"""
        screenshots = []
        
        if not screenshots_dir.exists():
            return screenshots
        
        # ãƒ–ãƒ©ã‚¦ã‚¶ç•ªå·ã”ã¨ã«æœ€æ–°ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—
        for browser_num in sorted(browser_status.keys()):
            status = browser_status[browser_num]
            
            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãƒ‘ã‚¹ã‚’å–å¾—
            screenshot_path = status.get('screenshot_path')
            if screenshot_path:
                # ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã¯çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
                if not Path(screenshot_path).is_absolute():
                    screenshot_path = screenshots_dir.parent / screenshot_path
                else:
                    screenshot_path = Path(screenshot_path)
            else:
                # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãƒ‘ã‚¹ãŒãªã„å ´åˆã¯ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æœ€æ–°ã®ã‚‚ã®ã‚’æ¢ã™
                browser_screenshots = sorted(
                    screenshots_dir.glob(f"browser_{browser_num}_*.png"),
                    key=lambda x: x.stat().st_mtime,
                    reverse=True
                )
                if browser_screenshots:
                    screenshot_path = browser_screenshots[0]
                else:
                    screenshot_path = None
            
            screenshot_info = {
                'screenshot_path': str(screenshot_path) if screenshot_path else None,
                'timestamp': status.get('screenshot_timestamp', status.get('last_activity', 'ä¸æ˜')),
                'status': status.get('status', 'unknown'),
                'keyword': status.get('current_keyword', None)
            }
            
            screenshots.append((browser_num, screenshot_info))
        
        return screenshots
    
    def calculate_statistics(self, samples: List[Dict]) -> Dict:
        """çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—"""
        stats = {
            'total_samples': len(samples),
            'nsfw_samples': len([s for s in samples if s.get('nsfw_label') != 'safe']),
            'by_category': {},
            'by_language': {},
            'by_source': {},
            'avg_text_length': 0,
            'total_text_length': 0
        }
        
        if samples:
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥
            for sample in samples:
                category = sample.get('category', 'unknown')
                stats['by_category'][category] = stats['by_category'].get(category, 0) + 1
            
            # è¨€èªåˆ¥
            for sample in samples:
                language = sample.get('language', 'unknown')
                stats['by_language'][language] = stats['by_language'].get(language, 0) + 1
            
            # ã‚½ãƒ¼ã‚¹åˆ¥
            for sample in samples:
                source = sample.get('source', 'unknown')
                stats['by_source'][source] = stats['by_source'].get(source, 0) + 1
            
            # å¹³å‡ãƒ†ã‚­ã‚¹ãƒˆé•·
            text_lengths = [s.get('text_length', 0) for s in samples if s.get('text_length')]
            if text_lengths:
                stats['total_text_length'] = sum(text_lengths)
                stats['avg_text_length'] = sum(text_lengths) / len(text_lengths)
        
        return stats
    
    def render_dashboard(self):
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
        st.set_page_config(
            page_title="SO8Tçµ±åˆ¶Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
            page_icon="ğŸ”",
            layout="wide"
        )
        
        st.title("ğŸ” SO8Tçµ±åˆ¶Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é›†ä¸­ç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
        st.markdown("---")
        
        # è‡ªå‹•æ›´æ–°è¨­å®š
        col1, col2, col3 = st.columns(3)
        with col1:
            auto_refresh = st.checkbox("è‡ªå‹•æ›´æ–°", value=True)
        with col2:
            refresh_interval = st.slider("æ›´æ–°é–“éš”ï¼ˆç§’ï¼‰", 1, 60, 5)
        with col3:
            if st.button("ğŸ”„ æ‰‹å‹•æ›´æ–°"):
                st.session_state.last_update = datetime.now()
                st.rerun()
        
        # è‡ªå‹•æ›´æ–°
        if auto_refresh:
            time.sleep(refresh_interval)
            st.rerun()
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã¿ï¼ˆå„ªå…ˆï¼‰
            dashboard_state = self.load_dashboard_state()
            
            samples = self.load_latest_samples()
            log_lines = self.load_log_data()
            
            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰çŠ¶æ…‹ã‹ã‚‰ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹ã¨SO8Tåˆ¤æ–­ã‚’å–å¾—
            if dashboard_state:
                browser_status = dashboard_state.get('browser_status', {})
                so8t_decisions = dashboard_state.get('so8t_decisions', [])
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ­ã‚°ã‹ã‚‰è§£æ
                browser_status = self.parse_browser_status_from_logs(log_lines)
                so8t_decisions = self.parse_so8t_decisions_from_logs(log_lines)
            
            stats = self.calculate_statistics(samples)
            
            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰çŠ¶æ…‹ã®çµ±è¨ˆã‚’æ›´æ–°
            if dashboard_state:
                stats['total_samples'] = dashboard_state.get('total_samples', stats['total_samples'])
                stats['nsfw_samples'] = dashboard_state.get('nsfw_samples', stats['nsfw_samples'])
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        st.subheader("ğŸ“Š å…¨ä½“çµ±è¨ˆ")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ç·ã‚µãƒ³ãƒ—ãƒ«æ•°", f"{stats['total_samples']:,}")
        with col2:
            st.metric("NSFWæ¤œçŸ¥ã‚µãƒ³ãƒ—ãƒ«", f"{stats['nsfw_samples']:,}", 
                     delta=f"{stats['nsfw_samples']/max(stats['total_samples'], 1)*100:.1f}%" if stats['total_samples'] > 0 else "0%")
        with col3:
            st.metric("å¹³å‡ãƒ†ã‚­ã‚¹ãƒˆé•·", f"{stats['avg_text_length']:.0f}" if stats['avg_text_length'] > 0 else "0")
        with col4:
            st.metric("ç·ãƒ†ã‚­ã‚¹ãƒˆé•·", f"{stats['total_text_length']:,}" if stats['total_text_length'] > 0 else "0")
        
        st.markdown("---")
        
        # ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹è¡¨ç¤º
        st.subheader("ğŸŒ ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹")
        
        if browser_status:
            # ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹ãƒ†ãƒ¼ãƒ–ãƒ«
            browser_df_data = []
            for browser_num, status in browser_status.items():
                browser_df_data.append({
                    'ãƒ–ãƒ©ã‚¦ã‚¶ç•ªå·': browser_num,
                    'çŠ¶æ…‹': status.get('status', 'unknown'),
                    'å‡¦ç†ä¸­ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰': status.get('current_keyword', 'ãªã—'),
                    'åé›†ã‚µãƒ³ãƒ—ãƒ«æ•°': status.get('samples_collected', 0),
                    'æœ€çµ‚æ´»å‹•': status.get('last_activity', 'ãªã—')
                })
            
            browser_df = pd.DataFrame(browser_df_data)
            st.dataframe(browser_df, use_container_width=True)
            
            # ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹ã®å¯è¦–åŒ–
            col1, col2 = st.columns(2)
            
            with col1:
                # çŠ¶æ…‹åˆ¥ãƒ–ãƒ©ã‚¦ã‚¶æ•°
                status_counts = {}
                for status in browser_status.values():
                    s = status.get('status', 'unknown')
                    status_counts[s] = status_counts.get(s, 0) + 1
                
                if status_counts:
                    st.bar_chart(status_counts)
            
            with col2:
                # ã‚µãƒ³ãƒ—ãƒ«åé›†æ•°ã®å¯è¦–åŒ–
                samples_by_browser = {
                    f"Browser {num}": status.get('samples_collected', 0)
                    for num, status in browser_status.items()
                }
                if samples_by_browser:
                    st.bar_chart(samples_by_browser)
        else:
            st.info("ãƒ–ãƒ©ã‚¦ã‚¶çŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        st.markdown("---")
        
        # ãƒ–ãƒ©ã‚¦ã‚¶ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆè¡¨ç¤º
        st.subheader("ğŸ“¸ ãƒ–ãƒ©ã‚¦ã‚¶ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰")
        
        # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
        screenshots_dir = None
        if dashboard_state:
            screenshots_dir_str = dashboard_state.get('screenshots_dir')
            if screenshots_dir_str:
                screenshots_dir = Path(screenshots_dir_str)
            else:
                screenshots_dir = self.output_dir / "screenshots"
        else:
            screenshots_dir = self.output_dir / "screenshots"
        
        # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿
        screenshots = self.load_browser_screenshots(screenshots_dir, browser_status)
        
        if screenshots:
            # ãƒ–ãƒ©ã‚¦ã‚¶ã”ã¨ã«ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’è¡¨ç¤º
            # 2åˆ—ã®ã‚°ãƒªãƒƒãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
            num_browsers = len(screenshots)
            cols_per_row = 2
            
            for row_start in range(0, num_browsers, cols_per_row):
                cols = st.columns(cols_per_row)
                for col_idx in range(cols_per_row):
                    browser_idx = row_start + col_idx
                    if browser_idx < num_browsers:
                        browser_num, screenshot_info = screenshots[browser_idx]
                        with cols[col_idx]:
                            st.markdown(f"**Browser {browser_num}**")
                            if screenshot_info['status']:
                                st.markdown(f"*çŠ¶æ…‹: {screenshot_info['status']}*")
                            if screenshot_info['keyword']:
                                st.markdown(f"*ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {screenshot_info['keyword']}*")
                            if screenshot_info['screenshot_path'] and Path(screenshot_info['screenshot_path']).exists():
                                try:
                                    img = Image.open(screenshot_info['screenshot_path'])
                                    st.image(img, use_container_width=True, caption=f"Browser {browser_num} - {screenshot_info['timestamp']}")
                                except Exception as e:
                                    st.error(f"ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                            else:
                                st.info("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            st.info("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŒé–‹å§‹ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        
        st.markdown("---")
        
        # SO8Tçµ±åˆ¶åˆ¤æ–­çµæœ
        st.subheader("ğŸ¤– SO8Tçµ±åˆ¶åˆ¤æ–­çµæœ")
        
        if so8t_decisions:
            # åˆ¤æ–­çµæœãƒ†ãƒ¼ãƒ–ãƒ«
            decisions_df_data = []
            for decision in so8t_decisions:
                decisions_df_data.append({
                    'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—': decision.get('timestamp', ''),
                    'ã‚¿ã‚¤ãƒ—': decision.get('type', 'unknown'),
                    'åˆ¤æ–­': decision.get('decision', 'unknown'),
                    'æ¨è«–': decision.get('reasoning', '')[:100] + '...' if len(decision.get('reasoning', '')) > 100 else decision.get('reasoning', '')
                })
            
            decisions_df = pd.DataFrame(decisions_df_data)
            st.dataframe(decisions_df, use_container_width=True)
            
            # åˆ¤æ–­çµæœã®å¯è¦–åŒ–
            col1, col2 = st.columns(2)
            
            with col1:
                # ã‚¿ã‚¤ãƒ—åˆ¥åˆ¤æ–­æ•°
                type_counts = {}
                for decision in so8t_decisions:
                    t = decision.get('type', 'unknown')
                    type_counts[t] = type_counts.get(t, 0) + 1
                
                if type_counts:
                    st.bar_chart(type_counts)
            
            with col2:
                # åˆ¤æ–­åˆ¥æ•°
                decision_counts = {}
                for decision in so8t_decisions:
                    d = decision.get('decision', 'unknown')
                    decision_counts[d] = decision_counts.get(d, 0) + 1
                
                if decision_counts:
                    st.bar_chart(decision_counts)
        else:
            st.info("SO8Tåˆ¤æ–­çµæœãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        st.markdown("---")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        st.subheader("ğŸ“ˆ ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if stats['by_category']:
                st.bar_chart(stats['by_category'])
        
        with col2:
            if stats['by_language']:
                st.bar_chart(stats['by_language'])
        
        with col3:
            if stats['by_source']:
                st.bar_chart(stats['by_source'])
        
        st.markdown("---")
        
        # æœ€æ–°ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        st.subheader("ğŸ“„ æœ€æ–°ã‚µãƒ³ãƒ—ãƒ«")
        
        if samples:
            # æœ€æ–°10ä»¶ã‚’è¡¨ç¤º
            recent_samples = samples[-10:]
            
            for i, sample in enumerate(reversed(recent_samples)):
                with st.expander(f"ã‚µãƒ³ãƒ—ãƒ« {len(samples) - i}: {sample.get('keyword', 'unknown')} - {sample.get('url', 'unknown')[:50]}..."):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write(f"**URL**: {sample.get('url', 'N/A')}")
                        st.write(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {sample.get('keyword', 'N/A')}")
                        st.write(f"**ã‚«ãƒ†ã‚´ãƒª**: {sample.get('category', 'N/A')}")
                        st.write(f"**è¨€èª**: {sample.get('language', 'N/A')}")
                    
                    with col2:
                        st.write(f"**ãƒ†ã‚­ã‚¹ãƒˆé•·**: {sample.get('text_length', 0):,}")
                        st.write(f"**NSFWãƒ©ãƒ™ãƒ«**: {sample.get('nsfw_label', 'N/A')}")
                        st.write(f"**NSFWä¿¡é ¼åº¦**: {sample.get('nsfw_confidence', 0):.2f}")
                        st.write(f"**åé›†æ™‚åˆ»**: {sample.get('crawled_at', 'N/A')}")
                    
                    # ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                    text = sample.get('text', '')
                    if text:
                        st.text_area("ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", text[:500] + "..." if len(text) > 500 else text, height=150, key=f"sample_{i}")
        else:
            st.info("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        st.markdown("---")
        
        # ãƒ­ã‚°è¡¨ç¤º
        st.subheader("ğŸ“‹ æœ€æ–°ãƒ­ã‚°")
        
        if log_lines:
            # æœ€å¾Œã®100è¡Œã‚’è¡¨ç¤º
            recent_logs = log_lines[-100:]
            log_text = "\n".join(recent_logs)
            st.text_area("ãƒ­ã‚°", log_text, height=300)
        else:
            st.info("ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ãƒ•ãƒƒã‚¿ãƒ¼
        st.markdown("---")
        st.markdown(f"**æœ€çµ‚æ›´æ–°**: {st.session_state.last_update.strftime('%Y-%m-%d %H:%M:%S')}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    dashboard = ScrapingDashboard()
    dashboard.render_dashboard()


if __name__ == "__main__":
    main()

