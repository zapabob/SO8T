#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SO8Tçµ±åˆ¶Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµ±ä¸€ç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

ã™ã¹ã¦ã®Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’çµ±åˆç®¡ç†ã™ã‚‹Streamlitãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

Usage:
    streamlit run scripts/dashboard/unified_scraping_dashboard.py
"""

import sys
import json
import time
import asyncio
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import pandas as pd
from PIL import Image

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False
    print("[ERROR] Streamlit not installed. Install with: pip install streamlit")
    sys.exit(1)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class UnifiedScrapingDashboard:
    """SO8Tçµ±åˆ¶Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµ±ä¸€ç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.output_dir = Path("D:/webdataset/processed")
        self.log_dir = Path("logs")
        self.checkpoint_dir = Path("D:/webdataset/checkpoints/pipeline")
        
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®šç¾©
        self.scraping_scripts = {
            'parallel_deep_research': {
                'name': 'ä¸¦åˆ—DeepResearch Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°',
                'script': 'scripts/data/parallel_deep_research_scraping.py',
                'batch': 'scripts/data/run_parallel_deep_research_scraping.bat',
                'description': '10å€‹ã®ãƒ–ãƒ©ã‚¦ã‚¶ã§ä¸¦åˆ—å®Ÿè¡Œã€SO8Tçµ±åˆ¶',
                'enabled': True
            },
            'arxiv_open_access': {
                'name': 'Arxivãƒ»ã‚ªãƒ¼ãƒ—ãƒ³ã‚¢ã‚¯ã‚»ã‚¹è«–æ–‡ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°',
                'script': 'scripts/data/arxiv_open_access_scraping.py',
                'batch': 'scripts/data/run_arxiv_background_scraping.bat',
                'description': 'Arxivå…¨ã‚¸ãƒ£ãƒ³ãƒ«ã¨ã‚ªãƒ¼ãƒ—ãƒ³ã‚¢ã‚¯ã‚»ã‚¹è«–æ–‡',
                'enabled': True
            },
            'auto_background': {
                'name': 'SO8Tçµ±åˆ¶å®Œå…¨è‡ªå‹•ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°',
                'script': 'scripts/data/so8t_auto_background_scraping.py',
                'batch': 'scripts/data/run_so8t_auto_background_scraping.bat',
                'description': 'å®Œå…¨è‡ªå‹•ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ',
                'enabled': True
            },
            'comprehensive_category': {
                'name': 'åŒ…æ‹¬çš„ã‚«ãƒ†ã‚´ãƒªWebã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°',
                'script': 'scripts/data/comprehensive_category_scraping.py',
                'batch': 'scripts/data/run_comprehensive_category_scraping.bat',
                'description': 'åºƒç¯„ãªã‚«ãƒ†ã‚´ãƒªã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°',
                'enabled': True
            },
            'deep_research_category': {
                'name': 'DeepResearchã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°',
                'script': 'scripts/data/deep_research_category_scraping.py',
                'batch': 'scripts/data/run_deep_research_scraping.bat',
                'description': 'DeepResearchã«ã‚ˆã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢',
                'enabled': True
            }
        }
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
        if 'last_update' not in st.session_state:
            st.session_state.last_update = datetime.now()
        if 'running_processes' not in st.session_state:
            st.session_state.running_processes = {}
        if 'error_logs' not in st.session_state:
            st.session_state.error_logs = []
    
    def check_process_status(self, script_key: str) -> Dict:
        """ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        status = {
            'running': False,
            'pid': None,
            'start_time': None,
            'error_count': 0,
            'last_error': None
        }
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰çŠ¶æ…‹ã‚’ç¢ºèª
        log_file = self.log_dir / f"{script_key}.log"
        if log_file.exists():
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    if lines:
                        # æœ€å¾Œã®è¡Œã‹ã‚‰çŠ¶æ…‹ã‚’ç¢ºèª
                        last_line = lines[-1]
                        if 'ERROR' in last_line or 'FAILED' in last_line:
                            status['error_count'] += 1
                            status['last_error'] = last_line.strip()
                        elif 'SUCCESS' in last_line or 'completed' in last_line.lower():
                            status['running'] = False
                        else:
                            # æœ€è¿‘ã®ãƒ­ã‚°ãŒã‚ã‚Œã°å®Ÿè¡Œä¸­ã¨åˆ¤æ–­
                            if len(lines) > 10:
                                status['running'] = True
            except Exception as e:
                logger.error(f"Failed to read log file: {e}")
        
        return status
    
    def load_all_status(self) -> Dict[str, Dict]:
        """ã™ã¹ã¦ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã¿"""
        all_status = {}
        
        for script_key, script_info in self.scraping_scripts.items():
            if script_info['enabled']:
                status = self.check_process_status(script_key)
                all_status[script_key] = {
                    **status,
                    'name': script_info['name'],
                    'description': script_info['description']
                }
        
        return all_status
    
    def load_error_logs(self) -> List[Dict]:
        """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿"""
        error_logs = []
        
        # å„ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ­ã‚°ã‹ã‚‰ã‚¨ãƒ©ãƒ¼ã‚’æŠ½å‡º
        for script_key in self.scraping_scripts.keys():
            log_file = self.log_dir / f"{script_key}.log"
            if log_file.exists():
                try:
                    with open(log_file, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                        for i, line in enumerate(lines):
                            if 'ERROR' in line or '404' in line or '200' in line:
                                error_logs.append({
                                    'timestamp': datetime.now().isoformat(),
                                    'script': script_key,
                                    'error': line.strip(),
                                    'line_number': i + 1
                                })
                except Exception as e:
                    logger.error(f"Failed to read error log: {e}")
        
        # æ™‚ç³»åˆ—ã§ã‚½ãƒ¼ãƒˆ
        error_logs.sort(key=lambda x: x['timestamp'], reverse=True)
        return error_logs[:100]  # æœ€æ–°100ä»¶
    
    def start_scraping_script(self, script_key: str) -> bool:
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’é–‹å§‹"""
        if script_key not in self.scraping_scripts:
            return False
        
        script_info = self.scraping_scripts[script_key]
        batch_file = PROJECT_ROOT / script_info['batch']
        
        if not batch_file.exists():
            logger.error(f"Batch file not found: {batch_file}")
            return False
        
        try:
            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
            process = subprocess.Popen(
                [str(batch_file)],
                cwd=str(PROJECT_ROOT),
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                creationflags=subprocess.CREATE_NEW_CONSOLE if sys.platform == 'win32' else 0
            )
            
            st.session_state.running_processes[script_key] = {
                'pid': process.pid,
                'start_time': datetime.now().isoformat(),
                'process': process
            }
            
            logger.info(f"Started scraping script: {script_key} (PID: {process.pid})")
            return True
        
        except Exception as e:
            logger.error(f"Failed to start script {script_key}: {e}")
            return False
    
    def stop_scraping_script(self, script_key: str) -> bool:
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’åœæ­¢"""
        if script_key not in st.session_state.running_processes:
            return False
        
        try:
            process_info = st.session_state.running_processes[script_key]
            process = process_info.get('process')
            
            if process:
                process.terminate()
                process.wait(timeout=10)
            
            del st.session_state.running_processes[script_key]
            logger.info(f"Stopped scraping script: {script_key}")
            return True
        
        except Exception as e:
            logger.error(f"Failed to stop script {script_key}: {e}")
            return False
    
    def render_dashboard(self):
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
        st.set_page_config(
            page_title="SO8Tçµ±åˆ¶Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµ±ä¸€ç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
            page_icon="ğŸ”",
            layout="wide"
        )
        
        st.title("ğŸ” SO8Tçµ±åˆ¶Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµ±ä¸€ç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
        st.markdown("---")
        
        # è‡ªå‹•æ›´æ–°è¨­å®š
        col1, col2, col3 = st.columns(3)
        with col1:
            auto_refresh = st.checkbox("è‡ªå‹•æ›´æ–°", value=True)
        with col2:
            refresh_interval = st.slider("æ›´æ–°é–“éš”ï¼ˆç§’ï¼‰", 1, 60, 5)
        with col3:
            if st.button("ğŸ”„ æ‰‹å‹•æ›´æ–°"):
                st.session_state.last_update = datetime.now()
                st.rerun()
        
        # è‡ªå‹•æ›´æ–°
        if auto_refresh:
            time.sleep(refresh_interval)
            st.rerun()
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            all_status = self.load_all_status()
            error_logs = self.load_error_logs()
        
        # å…¨ä½“çµ±è¨ˆ
        st.subheader("ğŸ“Š å…¨ä½“çµ±è¨ˆ")
        col1, col2, col3, col4 = st.columns(4)
        
        total_scripts = len(all_status)
        running_scripts = sum(1 for s in all_status.values() if s['running'])
        error_scripts = sum(1 for s in all_status.values() if s['error_count'] > 0)
        total_errors = sum(s['error_count'] for s in all_status.values())
        
        with col1:
            st.metric("ç·ã‚¹ã‚¯ãƒªãƒ—ãƒˆæ•°", total_scripts)
        with col2:
            st.metric("å®Ÿè¡Œä¸­", running_scripts, delta=f"{running_scripts/total_scripts*100:.1f}%" if total_scripts > 0 else "0%")
        with col3:
            st.metric("ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ", error_scripts, delta=f"{error_scripts/total_scripts*100:.1f}%" if total_scripts > 0 else "0%")
        with col4:
            st.metric("ç·ã‚¨ãƒ©ãƒ¼æ•°", total_errors)
        
        st.markdown("---")
        
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆç®¡ç†
        st.subheader("ğŸŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆç®¡ç†")
        
        for script_key, status in all_status.items():
            script_info = self.scraping_scripts[script_key]
            
            with st.expander(f"{status['name']} - {'ğŸŸ¢ å®Ÿè¡Œä¸­' if status['running'] else 'ğŸ”´ åœæ­¢ä¸­'}"):
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    st.write(f"**èª¬æ˜**: {status['description']}")
                    if status['running']:
                        st.write(f"**çŠ¶æ…‹**: ğŸŸ¢ å®Ÿè¡Œä¸­")
                    else:
                        st.write(f"**çŠ¶æ…‹**: ğŸ”´ åœæ­¢ä¸­")
                    
                    if status['error_count'] > 0:
                        st.warning(f"**ã‚¨ãƒ©ãƒ¼æ•°**: {status['error_count']}")
                        if status['last_error']:
                            st.error(f"**æœ€å¾Œã®ã‚¨ãƒ©ãƒ¼**: {status['last_error']}")
                
                with col2:
                    if script_key in st.session_state.running_processes:
                        if st.button("åœæ­¢", key=f"stop_{script_key}"):
                            self.stop_scraping_script(script_key)
                            st.rerun()
                    else:
                        if st.button("é–‹å§‹", key=f"start_{script_key}"):
                            self.start_scraping_script(script_key)
                            st.rerun()
        
        st.markdown("---")
        
        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¡¨ç¤º
        st.subheader("ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°")
        
        if error_logs:
            error_df = pd.DataFrame(error_logs)
            st.dataframe(error_df, use_container_width=True)
            
            # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ
            col1, col2 = st.columns(2)
            
            with col1:
                error_by_script = error_df.groupby('script').size()
                st.bar_chart(error_by_script)
            
            with col2:
                # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
                error_types = {}
                for error in error_logs:
                    error_text = error['error'].lower()
                    if '404' in error_text:
                        error_types['404 Not Found'] = error_types.get('404 Not Found', 0) + 1
                    elif '200' in error_text and 'empty' in error_text:
                        error_types['200 Empty Content'] = error_types.get('200 Empty Content', 0) + 1
                    elif 'timeout' in error_text:
                        error_types['Timeout'] = error_types.get('Timeout', 0) + 1
                    else:
                        error_types['Other'] = error_types.get('Other', 0) + 1
                
                if error_types:
                    st.bar_chart(error_types)
        else:
            st.info("ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“")
        
        st.markdown("---")
        
        # å…¨è‡ªå‹•ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆ¶å¾¡
        st.subheader("âš™ï¸ å…¨è‡ªå‹•ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆ¶å¾¡")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸš€ å…¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹å§‹", use_container_width=True):
                for script_key in self.scraping_scripts.keys():
                    if script_key not in st.session_state.running_processes:
                        self.start_scraping_script(script_key)
                st.success("ã™ã¹ã¦ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’é–‹å§‹ã—ã¾ã—ãŸ")
                st.rerun()
        
        with col2:
            if st.button("ğŸ›‘ å…¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆåœæ­¢", use_container_width=True):
                for script_key in list(st.session_state.running_processes.keys()):
                    self.stop_scraping_script(script_key)
                st.success("ã™ã¹ã¦ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’åœæ­¢ã—ã¾ã—ãŸ")
                st.rerun()
        
        # ãƒ•ãƒƒã‚¿ãƒ¼
        st.markdown("---")
        st.markdown(f"**æœ€çµ‚æ›´æ–°**: {st.session_state.last_update.strftime('%Y-%m-%d %H:%M:%S')}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    dashboard = UnifiedScrapingDashboard()
    dashboard.render_dashboard()


if __name__ == "__main__":
    main()





