{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SO8Tç¾¤Transformer 8bité‡å­åŒ–GGUFå¤‰æ› (GoogleColab)\n",
        "\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€SO8Tç¾¤Transformerãƒ¢ãƒ‡ãƒ«ã‚’8bité‡å­åŒ–GGUFå½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚\n",
        "\n",
        "## ç‰¹å¾´\n",
        "- ğŸš€ **SO8Tç¾¤æ§‹é€ ã®ä¿æŒ**: SO(8)ç¾¤å›è»¢ã¨éå¯æ›ã‚²ãƒ¼ãƒˆ\n",
        "- ğŸ§  **Triality reasoning**: 3ã¤ã®æ¨è«–ãƒ˜ãƒƒãƒ‰ï¼ˆtask, safety, authorityï¼‰\n",
        "- âš¡ **8bité‡å­åŒ–**: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å¤§å¹…å‰Šæ¸›\n",
        "- ğŸ“¦ **GGUFå½¢å¼**: åŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«ä¿å­˜ã¨èª­ã¿è¾¼ã¿\n",
        "- ğŸ”§ **GoogleColabæœ€é©åŒ–**: ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã¨å®Ÿè¡Œé€Ÿåº¦ã‚’æœ€é©åŒ–\n",
        "\n",
        "## SO8Tç¾¤ã¨ã¯ï¼Ÿ\n",
        "SO8Tç¾¤ã¯8æ¬¡å…ƒå›è»¢ç¾¤SO(8)ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸç‰¹æ®ŠãªTransformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ï¼š\n",
        "- **éå¯æ›ã‚²ãƒ¼ãƒˆ**: R_safe â†’ R_cmd ã®éå¯æ›ç©\n",
        "- **PETæ­£å‰‡åŒ–**: æ™‚ç³»åˆ—ä¸€è²«æ€§ã«ã‚ˆã‚‹ç¾¤ã®æ…£æ€§\n",
        "- **å®‰å…¨äººæ ¼**: å­¦ç¿’ä¸­ã«ç¾¤æ§‹é€ ãŒå´©å£Šã—ãªã„è¨­è¨ˆ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers accelerate bitsandbytes\n",
        "!pip install numpy tqdm\n",
        "\n",
        "# ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã®ãŸã‚ã®ç’°å¢ƒå¤‰æ•°è¨­å®š\n",
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "print(\"âœ… ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "\n",
        "# ãƒ­ã‚°è¨­å®š\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# GPUæƒ…å ±è¡¨ç¤º\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"ğŸš€ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸ GPU not available, using CPU\")\n",
        "\n",
        "print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
