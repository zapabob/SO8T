# SO8TÃ—ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLM A/Bãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# 4æ¡ä»¶ï¼ˆå›è»¢æœ‰/ç„¡Ã—PETæœ‰/ç„¡ï¼‰ã®æ¯”è¼ƒå­¦ç¿’

param(
    [string]$ModelPath = "../Qwen2-VL-2B-Instruct",
    [string]$ConfigPath = "configs/train.qlora.json",
    [string]$OutputDir = "./ab_test_results",
    [int]$Epochs = 2,
    [int]$BatchSize = 1
)

Write-Host "ğŸ§ª SO8TÃ—ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLM A/Bãƒ†ã‚¹ãƒˆé–‹å§‹..." -ForegroundColor Green

# ä»®æƒ³ç’°å¢ƒã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
Write-Host "ğŸ”§ ä»®æƒ³ç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆä¸­..." -ForegroundColor Yellow
.\.venv\Scripts\Activate.ps1

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
Write-Host "ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆä¸­..." -ForegroundColor Yellow
New-Item -ItemType Directory -Path $OutputDir -Force | Out-Null

# A/Bãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œ
Write-Host "ğŸ¯ A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­..." -ForegroundColor Yellow

$abTestScript = @"
import sys
import os
import json
import torch
import numpy as np
from pathlib import Path
from datetime import datetime
import time

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append('src')

from training.trainer_with_pet import SO8TIntegratedTrainer
from modules.qwen2vl_wrapper import create_so8t_qwen2vl_model
from io.ocr_summary import OCRSummaryProcessor
from audit.sqlite_logger import SQLiteAuditLogger
from eval.metrics import SO8TEvaluator

def create_test_dataset():
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
    print("ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆä¸­...")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    sample_texts = [
        "ç”»åƒã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
        "ã“ã®å†™çœŸã«ã¯ä½•ãŒå†™ã£ã¦ã„ã¾ã™ã‹ï¼Ÿ",
        "è¦–è¦šçš„ãªå†…å®¹ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚",
        "ç”»åƒã®è©³ç´°ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
        "ã“ã®ç”»åƒã‹ã‚‰ä½•ãŒåˆ†ã‹ã‚Šã¾ã™ã‹ï¼Ÿ",
        "å†™çœŸã®å†…å®¹ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚",
        "ç”»åƒã«å†™ã£ã¦ã„ã‚‹ç‰©ä½“ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚",
        "è¦–è¦šçš„ãªæƒ…å ±ã‚’è§£é‡ˆã—ã¦ãã ã•ã„ã€‚",
        "ç”»åƒã®ç‰¹å¾´ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
        "å†™çœŸã®åˆ†æçµæœã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
    ]
    
    # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’å–å¾—
    from transformers import AutoTokenizer
    tokenizer = AutoTokenizer.from_pretrained('$ModelPath')
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
    dataset = []
    for text in sample_texts:
        # å…¥åŠ›ã¨ãƒ©ãƒ™ãƒ«ã‚’åŒã˜ã«ã™ã‚‹ï¼ˆè‡ªå·±å›å¸°å­¦ç¿’ï¼‰
        inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
        labels = inputs["input_ids"].clone()
        
        dataset.append({
            "input_ids": inputs["input_ids"].squeeze(0),
            "attention_mask": inputs["attention_mask"].squeeze(0),
            "labels": labels.squeeze(0)
        })
    
    print(f"ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {len(dataset)}")
    return dataset

def run_ab_test():
    """A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print("ğŸ§ª SO8TÃ—ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLM A/Bãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
    test_dataset = create_test_dataset()
    
    # 4æ¡ä»¶ã®è¨­å®š
    test_conditions = [
        {
            "name": "baseline",
            "description": "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆå›è»¢ãªã—ã€PETãªã—ï¼‰",
            "rotation_enabled": False,
            "pet_enabled": False
        },
        {
            "name": "rotation_only",
            "description": "å›è»¢ã‚²ãƒ¼ãƒˆã®ã¿",
            "rotation_enabled": True,
            "pet_enabled": False
        },
        {
            "name": "pet_only",
            "description": "PETæå¤±ã®ã¿",
            "rotation_enabled": False,
            "pet_enabled": True
        },
        {
            "name": "full_so8t",
            "description": "å®Œå…¨SO8Tï¼ˆå›è»¢+PETï¼‰",
            "rotation_enabled": True,
            "pet_enabled": True
        }
    ]
    
    results = {}
    
    for condition in test_conditions:
        print(f"\\nğŸ¯ æ¡ä»¶: {condition['description']}")
        print("=" * 50)
        
        # æ¡ä»¶åˆ¥ã®è¨­å®šã‚’ä½œæˆ
        condition_config = {
            "learning_rate": 2e-4,
            "batch_size": $BatchSize,
            "gradient_accumulation_steps": 8,
            "num_epochs": $Epochs,
            "warmup_steps": 50,
            "max_grad_norm": 1.0,
            "weight_decay": 0.01,
            "lora_rank": 64,
            "lora_alpha": 128,
            "lora_dropout": 0.1,
            "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
            "rotation_gate_enabled": condition["rotation_enabled"],
            "pet_loss_enabled": condition["pet_enabled"],
            "pet_lambda_schedule": {
                "max_lambda": 0.1,
                "warmup_steps": 25,
                "main_steps": 100,
                "anneal_steps": 25
            }
        }
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        config_path = f"$OutputDir/config_{condition['name']}.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(condition_config, f, indent=2, ensure_ascii=False)
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        condition_output_dir = f"$OutputDir/{condition['name']}"
        os.makedirs(condition_output_dir, exist_ok=True)
        
        try:
            # å­¦ç¿’é–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
            start_time = time.time()
            
            # å­¦ç¿’å™¨ã‚’åˆæœŸåŒ–
            trainer = SO8TIntegratedTrainer(
                model_path='$ModelPath',
                config_path=config_path,
                output_dir=condition_output_dir
            )
            
            # å­¦ç¿’å®Ÿè¡Œ
            print(f"ğŸš€ å­¦ç¿’é–‹å§‹: {condition['description']}")
            trainer.train(test_dataset)
            
            # å­¦ç¿’æ™‚é–“ã‚’è¨˜éŒ²
            training_time = time.time() - start_time
            
            # ç°¡å˜ãªæ¨è«–ãƒ†ã‚¹ãƒˆ
            print(f"ğŸ§ª æ¨è«–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
            test_prompts = [
                "ç”»åƒã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
                "ã“ã®å†™çœŸã«ã¯ä½•ãŒå†™ã£ã¦ã„ã¾ã™ã‹ï¼Ÿ",
                "è¦–è¦šçš„ãªå†…å®¹ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"
            ]
            
            inference_results = []
            for prompt in test_prompts:
                try:
                    response = trainer.generate_with_ocr(prompt)
                    inference_results.append({
                        "prompt": prompt,
                        "response": response,
                        "success": True
                    })
                except Exception as e:
                    inference_results.append({
                        "prompt": prompt,
                        "response": f"ERROR: {str(e)}",
                        "success": False
                    })
            
            # çµæœã‚’è¨˜éŒ²
            results[condition['name']] = {
                "condition": condition,
                "training_time": training_time,
                "inference_results": inference_results,
                "success_rate": np.mean([r["success"] for r in inference_results]),
                "output_dir": condition_output_dir,
                "config_path": config_path
            }
            
            print(f"âœ… æ¡ä»¶å®Œäº†: {condition['description']}")
            print(f"   å­¦ç¿’æ™‚é–“: {training_time:.2f}ç§’")
            print(f"   æˆåŠŸç‡: {results[condition['name']]['success_rate']:.3f}")
            
        except Exception as e:
            print(f"âŒ æ¡ä»¶å¤±æ•—: {condition['description']} - {str(e)}")
            results[condition['name']] = {
                "condition": condition,
                "error": str(e),
                "success": False
            }
    
    return results

def analyze_results(results):
    """çµæœã‚’åˆ†æ"""
    print("\\nğŸ“Š A/Bãƒ†ã‚¹ãƒˆçµæœåˆ†æ")
    print("=" * 60)
    
    # æˆåŠŸã—ãŸæ¡ä»¶ã®ã¿ã‚’åˆ†æ
    successful_results = {k: v for k, v in results.items() if v.get("success", True) and "error" not in v}
    
    if not successful_results:
        print("âŒ æˆåŠŸã—ãŸæ¡ä»¶ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # å­¦ç¿’æ™‚é–“ã®æ¯”è¼ƒ
    print("\\nâ±ï¸ å­¦ç¿’æ™‚é–“æ¯”è¼ƒ:")
    for name, result in successful_results.items():
        print(f"  {result['condition']['description']}: {result['training_time']:.2f}ç§’")
    
    # æˆåŠŸç‡ã®æ¯”è¼ƒ
    print("\\nğŸ“ˆ æˆåŠŸç‡æ¯”è¼ƒ:")
    for name, result in successful_results.items():
        print(f"  {result['condition']['description']}: {result['success_rate']:.3f}")
    
    # æœ€è‰¯ã®æ¡ä»¶ã‚’ç‰¹å®š
    best_condition = max(successful_results.items(), key=lambda x: x[1]['success_rate'])
    print(f"\\nğŸ† æœ€è‰¯ã®æ¡ä»¶: {best_condition[1]['condition']['description']}")
    print(f"   æˆåŠŸç‡: {best_condition[1]['success_rate']:.3f}")
    print(f"   å­¦ç¿’æ™‚é–“: {best_condition[1]['training_time']:.2f}ç§’")
    
    # è©³ç´°ãªæ¯”è¼ƒåˆ†æ
    print("\\nğŸ” è©³ç´°åˆ†æ:")
    
    # å›è»¢ã‚²ãƒ¼ãƒˆã®åŠ¹æœ
    rotation_conditions = [r for r in successful_results.values() if r['condition']['rotation_enabled']]
    no_rotation_conditions = [r for r in successful_results.values() if not r['condition']['rotation_enabled']]
    
    if rotation_conditions and no_rotation_conditions:
        rotation_avg = np.mean([r['success_rate'] for r in rotation_conditions])
        no_rotation_avg = np.mean([r['success_rate'] for r in no_rotation_conditions])
        print(f"  å›è»¢ã‚²ãƒ¼ãƒˆåŠ¹æœ: {rotation_avg:.3f} vs {no_rotation_avg:.3f} (å·®: {rotation_avg - no_rotation_avg:+.3f})")
    
    # PETæå¤±ã®åŠ¹æœ
    pet_conditions = [r for r in successful_results.values() if r['condition']['pet_enabled']]
    no_pet_conditions = [r for r in successful_results.values() if not r['condition']['pet_enabled']]
    
    if pet_conditions and no_pet_conditions:
        pet_avg = np.mean([r['success_rate'] for r in pet_conditions])
        no_pet_avg = np.mean([r['success_rate'] for r in no_pet_conditions])
        print(f"  PETæå¤±åŠ¹æœ: {pet_avg:.3f} vs {no_pet_avg:.3f} (å·®: {pet_avg - no_pet_avg:+.3f})")
    
    return successful_results

def main():
    print("ğŸ§ª SO8TÃ—ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLM A/Bãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    # ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚’è¡¨ç¤º
    print(f"ğŸ”§ ãƒ‡ãƒã‚¤ã‚¹: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")
    print(f"ğŸ’¾ ãƒ¡ãƒ¢ãƒª: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB" if torch.cuda.is_available() else "CPUä½¿ç”¨")
    
    # A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    results = run_ab_test()
    
    # çµæœã‚’åˆ†æ
    successful_results = analyze_results(results)
    
    # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    results_file = "$OutputDir/ab_test_results.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "test_conditions": len(results),
            "successful_conditions": len(successful_results) if successful_results else 0,
            "results": results
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\\nğŸ“ çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {results_file}")
    print("âœ… A/Bãƒ†ã‚¹ãƒˆå®Œäº†ï¼")

if __name__ == "__main__":
    main()
"@

# A/Bãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
$abTestScript | py -3

if ($LASTEXITCODE -eq 0) {
    Write-Host "âœ… A/Bãƒ†ã‚¹ãƒˆå®Œäº†ï¼" -ForegroundColor Green
    Write-Host "ğŸ“ çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: $OutputDir" -ForegroundColor Cyan
    Write-Host "ğŸ“Š çµæœãƒ•ã‚¡ã‚¤ãƒ«: $OutputDir/ab_test_results.json" -ForegroundColor Cyan
} else {
    Write-Error "âŒ A/Bãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    exit 1
}
