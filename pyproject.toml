[project]
name = "so8t-safe-agent"
version = "0.1.0"
description = "SO8T Safe Agent - Advanced multimodal LLM with safety features"
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}

dependencies = [
    # PyTorch and CUDA support
    # Note: PyTorch with CUDA 12.1 should be installed from PyTorch index
    # Install with: uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    "torch>=2.0.0",
    "torchvision>=0.15.0",
    "torchaudio>=2.0.0",
    
    # Transformers and model libraries
    "transformers>=4.35.0",
    "tokenizers>=0.14.0",
    "accelerate>=0.24.0",
    "peft>=0.10.0",
    "bitsandbytes>=0.41.0",
    
    # Data processing and utilities
    "numpy>=1.24.0",
    "pandas>=2.0.0",
    "scikit-learn>=1.3.0",
    "tqdm>=4.65.0",
    "pyyaml>=6.0",
    "pyarrow>=12.0.0",
    
    # Visualization and analysis
    "matplotlib>=3.7.0",
    "seaborn>=0.12.0",
    "plotly>=5.15.0",
    
    # Bayesian optimization
    "optuna>=3.4.0",
    "optuna-dashboard>=0.13.0",
    
    # Logging and monitoring
    "wandb>=0.15.0",
    "tensorboard>=2.13.0",
    "mlflow>=2.8.0",
    "psutil>=5.9.0",
    "GPUtil>=1.4.0",
    
    # Web and API
    "fastapi>=0.100.0",
    "uvicorn>=0.23.0",
    "pydantic>=2.0.0",
    "requests>=2.31.0",
    
    # Development and testing
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "flake8>=6.0.0",
    "mypy>=1.5.0",
    
    # Documentation
    "sphinx>=7.0.0",
    "sphinx-rtd-theme>=1.3.0",
    "mkdocs>=1.5.0",
    "mkdocs-material>=9.2.0",
    
    # System utilities
    "python-dotenv>=1.0.0",
    "click>=8.1.0",
    "rich>=13.5.0",
    "typer>=0.9.0",
    
    # Gemini API (Computer Use Preview統合用)
    "google-genai>=1.40.0",
]

[project.optional-dependencies]
# Flash Attention (optional, requires CUDA and build tools)
# Note: Windows build is difficult, use WSL2 or Linux for installation
flash-attention = [
    "flash-attn==2.5.0; platform_system != 'Windows'",
]

# GGUF support (requires llama.cpp)
gguf = [
    "llama-cpp-python>=0.2.0",
]

# Additional model support
models = [
    "openai>=1.0.0",
    "anthropic>=0.7.0",
]

# Database support
database = [
    "sqlalchemy>=2.0.0",
    "alembic>=1.12.0",
]

# Message queues
queues = [
    "redis>=4.6.0",
    "celery>=5.3.0",
]

# Monitoring and observability
monitoring = [
    "prometheus-client>=0.17.0",
    "grafana-api>=1.0.3",
]

# Security
security = [
    "cryptography>=41.0.0",
    "bcrypt>=4.0.0",
]

# Cloud storage
cloud = [
    "boto3>=1.28.0",
    "azure-storage-blob>=12.17.0",
    "google-cloud-storage>=2.10.0",
]

# All optional dependencies
all = [
    "so8t-safe-agent[flash-attention,gguf,models,database,queues,monitoring,security,cloud]",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["so8t_core", "models", "utils"]

[tool.uv]
dev-dependencies = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "flake8>=6.0.0",
    "mypy>=1.5.0",
]

[tool.black]
line-length = 120
target-version = ['py310', 'py311', 'py312']

[tool.isort]
profile = "black"
line_length = 120

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false

