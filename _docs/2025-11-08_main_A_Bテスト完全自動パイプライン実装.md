# A/Bテスト完全自動パイプライン実装ログ

## 実装情報
- **日付**: 2025-11-08
- **Worktree**: main
- **機能名**: A/Bテスト完全自動パイプライン
- **実装者**: AI Agent

## 実装内容

### 1. 完全自動パイプラインスクリプト作成

**ファイル**: `scripts/pipelines/complete_ab_test_post_processing_pipeline.py` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: 2025-11-08  
**備考**: A/BテストからGGUF変換、Ollamaインポート、日本語パフォーマンステストまでを完全自動化。subprocess経由でA/Bテストスクリプトを実行し、独立性を保つ設計。

- `CompleteABTestPostProcessingPipeline`クラス: メインパイプラインクラス
- `AudioNotifier`クラス: 音声通知クラス
- `WinnerModelDeterminer`クラス: 勝者モデル判定クラス
- `GGUFConverter`クラス: GGUF変換クラス
- `OllamaImporter`クラス: Ollamaインポートクラス
- `step1_run_ab_test()`: A/Bテスト実行
- `step2_determine_winner()`: 勝者モデル判定（accuracy + F1 macro比較）
- `step3_convert_to_gguf()`: GGUF変換（F16 + Q8_0）
- `step4_import_to_ollama()`: Ollamaインポート
- `step5_run_japanese_performance_test()`: 日本語パフォーマンステスト実行
- `run_complete_pipeline()`: 完全パイプライン実行
- 各ステップ完了時に音声通知を再生

### 2. 設定ファイル作成

**ファイル**: `configs/complete_ab_test_post_processing_config.yaml` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: 2025-11-08  
**備考**: A/Bテスト、GGUF変換、Ollama、日本語テストの設定を統合。YAML形式で設定を一元管理。

- A/Bテスト設定: base_model, retrained_model, test_data, output_dir
- GGUF変換設定: convert_script, output_dir, quantizations
- Ollama設定: model_name, modelfile_dir
- 日本語パフォーマンステスト設定: output_dir, test_categories
- デバイス設定: cuda/cpu

### 3. 日本語パフォーマンステストスクリプト作成

**ファイル**: `scripts/testing/japanese_llm_performance_test.py` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: 2025-11-08  
**備考**: 5つのテストカテゴリを実装し、結果を評価・ドキュメント化。Ollamaコマンド経由でテストを実行し、JSON形式とMarkdown形式で結果を保存。worktree名を含むファイル名を自動生成。

- `JapaneseLLMPerformanceTester`クラス: 日本語パフォーマンステスター
- `test_understanding()`: 日本語理解テスト
- `test_generation()`: 日本語生成テスト
- `test_reasoning()`: 日本語推論テスト
- `test_dialogue()`: 日本語対話テスト
- `test_technical()`: 専門用語テスト
- `evaluate_response()`: 応答評価（簡易版）
- `run_all_tests()`: 全テスト実行
- `_generate_markdown_report()`: Markdown形式レポート生成
- テスト結果をJSON形式とMarkdown形式で保存
- worktree名を含むファイル名生成

## 作成・変更ファイル
- `scripts/pipelines/complete_ab_test_post_processing_pipeline.py` (新規作成)
- `configs/complete_ab_test_post_processing_config.yaml` (新規作成)
- `scripts/testing/japanese_llm_performance_test.py` (新規作成)

## 設計判断

1. **A/Bテスト実行**: subprocessで既存スクリプトを実行し、独立性を保つ
2. **勝者モデル判定**: accuracy + F1 macroの平均スコアで判定
3. **GGUF変換**: F16（フル精度）とQ8_0（8-bit量子化）の両方を変換
4. **Ollamaインポート**: Q8_0を優先、なければF16を使用
5. **日本語テスト**: 5つのカテゴリで包括的な評価
6. **音声通知**: 各ステップ完了時に再生

## データフロー

```
A/Bテスト実行
  ↓
勝者モデル判定（accuracy + F1 macro比較）
  ↓
GGUF変換（F16 + Q8_0）
  ↓
Ollamaインポート（Q8_0優先）
  ↓
日本語パフォーマンステスト実行
  ↓
結果ドキュメント化（JSON + Markdown）
```

## 依存関係

### 既存実装の活用
- `scripts/evaluation/ab_test_borea_phi35_original_vs_so8t.py` - A/Bテスト実行
- `external/llama.cpp-master/convert_hf_to_gguf.py` - GGUF変換
- `ollama` - Ollamaコマンドラインツール

### 外部ツール
- `ollama`: Ollamaモデル管理
- `subprocess`: 外部スクリプト実行

## 使用方法

### 基本実行

```bash
# 設定ファイルを使用
py scripts/pipelines/complete_ab_test_post_processing_pipeline.py \
    --config configs/complete_ab_test_post_processing_config.yaml
```

### カスタム設定

設定ファイルを編集して、モデルパスや出力ディレクトリを変更できます。

## 出力ファイル

### A/Bテスト結果
- `eval_results/ab_test_borea_phi35_original_vs_so8t/ab_test_results.json`
- `eval_results/ab_test_borea_phi35_original_vs_so8t/ab_test_report.html`
- `eval_results/ab_test_borea_phi35_original_vs_so8t/comparison_chart.png`

### GGUFモデル
- `D:/webdataset/gguf_models/{model_name}/{model_name}_f16.gguf`
- `D:/webdataset/gguf_models/{model_name}/{model_name}_q8_0.gguf`

### Modelfile
- `modelfiles/{model_name}.modelfile`

### 日本語パフォーマンステスト結果
- `_docs/yyyy-mm-dd_{worktree_name}_japanese_llm_performance_test_{model_name}.json`
- `_docs/yyyy-mm-dd_{worktree_name}_japanese_llm_performance_test_{model_name}.md`

### パイプライン結果
- `eval_results/ab_test_borea_phi35_original_vs_so8t/complete_pipeline_results.json`

## テスト計画

1. **A/Bテスト実行テスト**: 正常にA/Bテストが実行されることを確認
2. **勝者判定テスト**: 勝者モデルが正しく判定されることを確認
3. **GGUF変換テスト**: F16とQ8_0の両方が正常に変換されることを確認
4. **Ollamaインポートテスト**: モデルが正常にOllamaにインポートされることを確認
5. **日本語テストテスト**: 5つのテストカテゴリが正常に実行されることを確認

## 運用注意事項

### データ収集ポリシー
- 利用条件を守りつつ、高信頼ソースとして優先使用
- robots.txt遵守を徹底
- 個人情報・機密情報の除外を徹底

### NSFWコーパス運用
- **主目的**: 安全判定と拒否挙動の学習（生成目的ではない）
- モデル設計とドキュメントに明記
- 分類器は検出・拒否用途のみ

### /thinkエンドポイント運用
- 四重Thinking部（`<think-*>`）は外部非公開を徹底
- `<final>`のみ返す実装を維持
- 監査ログでThinkingハッシュを記録（内容は非公開）

