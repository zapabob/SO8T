# Borea-Phi-3.5-mini 完全パイプライン実装ログ

## 実装日時
2025-11-07

## 概要
Borea-Phi-3.5-mini-Instruct-Commonをベースに、SO8T+PET焼きこみ、日本語特化ファインチューニング、四値分類（ALLOW/ESCALATION/DENY/REFUSE）学習、量子化、ベンチマーク評価まで一貫したパイプラインを実装しました。

## 実装内容

### 1. データ処理スクリプト

#### `scripts/clean_japanese_dataset.py`
- 重複除去（MD5ハッシュベース）
- 品質フィルタリング（品質スコア0.7以上）
- 日本語含有率チェック（30%以上）
- 長さ正規化（50-5000文字）
- 統計レポート出力

#### `scripts/label_four_class_dataset.py`
- 四値分類ラベル付け（ALLOW/ESCALATION/DENY/REFUSE）
- キーワードベース自動分類
- クラスバランス調整（オプション）
- 統計レポート出力

#### `scripts/split_dataset.py`
- 統計的ランダム分割（訓練80%/検証10%/テスト10%）
- 層化サンプリング対応
- sklearn.model_selection.train_test_split使用

### 2. 学習スクリプト

#### `scripts/finetune_borea_japanese.py`
- QLoRA 8bit学習
- 電源断リカバリー対応（5分間隔チェックポイント）
- セッション管理
- 自動再開機能
- BitsAndBytesConfig使用

#### `scripts/train_four_class_classifier.py`
- 四値分類モデル（ベースモデル + 分類ヘッド）
- Focal Loss + クラス重み対応
- 評価メトリクス（F1macro、誤検知率、正解率）
- 混同行列計算

#### `scripts/evaluate_four_class.py`
- 四値分類評価
- F1macro、誤検知率、正解率計算
- 混同行列プロット（matplotlib/seaborn）
- JSON形式レポート出力

### 3. 統合パイプライン

#### `scripts/run_borea_complete_pipeline.py`
- 全フェーズ統合実行
- データ収集（合成 + 公開 + Webクロール）
- データクレンジング
- ラベル付け
- データ分割
- 日本語ファインチューニング
- 四値分類学習
- 評価
- 音声通知対応

### 4. 設定ファイル

#### `configs/finetune_borea_japanese.yaml`
- Borea-Phi-3.5-mini日本語ファインチューニング設定
- QLoRA 8bit設定
- 学習ハイパーパラメータ

#### `configs/train_four_class.yaml`
- 四値分類学習設定
- Focal Loss設定
- クラス重み設定

## 実行フロー

### Phase 1: データ収集
```bash
# 合成データセット生成
py -3 scripts/generate_synthetic_japanese.py --output data/synthetic_data.jsonl --total_samples 50000

# 公開データセット収集 + Webクロール
cd so8t-mmllm
py -3 scripts/data/collect_japanese_data.py --target 50000 --workers 4
```

### Phase 2: データ処理
```bash
# データクレンジング
py -3 scripts/clean_japanese_dataset.py --input data/collected --output data/cleaned

# 四値分類ラベル付け
py -3 scripts/label_four_class_dataset.py --input data/cleaned --output data/labeled

# データ分割
py -3 scripts/split_dataset.py --input data/labeled --output data/splits
```

### Phase 3: 学習
```bash
# 日本語ファインチューニング
py -3 scripts/finetune_borea_japanese.py --config configs/finetune_borea_japanese.yaml --auto-resume

# 四値分類学習
py -3 scripts/train_four_class_classifier.py --config configs/train_four_class.yaml
```

### Phase 4: 評価
```bash
# 四値分類評価
py -3 scripts/evaluate_four_class.py --model checkpoints/borea_phi35_mini_four_class/final_model --test data/splits/test.jsonl
```

### 統合実行
```bash
# 全フェーズ実行
py -3 scripts/run_borea_complete_pipeline.py --phase all --target-samples 100000

# 個別フェーズ実行
py -3 scripts/run_borea_complete_pipeline.py --phase data_collection
py -3 scripts/run_borea_complete_pipeline.py --phase finetune
```

## データ収集機能

### 合成データセット
- ドメイン特化（防衛・航空宇宙・運輸・一般）
- Q&Aペア生成
- 三重推論サンプル（ALLOW/ESCALATION/DENY）

### 公開データセット
- HuggingFace Datasets:
  - Wikipedia日本語
  - CC-100日本語
  - MC4日本語

### Webクロール
- 倫理的クロール（robots.txt遵守）
- 対象サイト:
  - 防衛省
  - JAXA
  - 国土交通省
  - 経済産業省
  - その他政府・公共サイト

## 評価メトリクス

### 四値分類メトリクス
- **F1macro**: (F1_ALLOW + F1_ESCALATION + F1_DENY + F1_REFUSE) / 4
- **誤検知率**: 危険な要求を誤ってALLOWする率
- **正解率**: 全体のAccuracy
- **混同行列**: 4×4マトリックス

## 電源断対応

### チェックポイント管理
- 5分間隔自動保存
- 最大10個のバックアップローテーション
- セッション管理（固有ID）
- 異常終了時の自動復旧

### シグナルハンドリング
- SIGINT, SIGTERM, SIGBREAK対応
- 緊急保存機能
- データ整合性保証（JSON）

## 音声通知

完了時に音声通知を再生:
- ファイル: `.cursor/marisa_owattaze.wav`
- PowerShell経由で再生

## 次のステップ

1. 段階A: ベースGGUF変換
2. 段階B: SO8T+PET焼きこみ
3. 段階D: HFベンチマーク評価
4. 段階E: Q5量子化

## 実装ファイル一覧

### 新規作成
- [OK] `scripts/clean_japanese_dataset.py`
- [OK] `scripts/label_four_class_dataset.py`
- [OK] `scripts/split_dataset.py`
- [OK] `scripts/finetune_borea_japanese.py`
- [OK] `scripts/train_four_class_classifier.py`
- [OK] `scripts/evaluate_four_class.py`
- [OK] `scripts/run_borea_complete_pipeline.py`
- [OK] `configs/finetune_borea_japanese.yaml`
- [OK] `configs/train_four_class.yaml`

### 既存拡張
- [OK] `so8t-mmllm/scripts/data/collect_japanese_data.py` - Webクロール機能統合済み
- [OK] `scripts/generate_synthetic_japanese.py` - 既存実装使用

## 注意事項

1. データ収集は長時間かかる可能性があります（数時間〜数日）
2. 電源断リカバリー機能により、中断しても自動再開可能
3. Webクロールはrobots.txtを遵守し、レート制限を設けています
4. 学習には十分なGPUメモリが必要です（RTX3080 12GB以上推奨）






