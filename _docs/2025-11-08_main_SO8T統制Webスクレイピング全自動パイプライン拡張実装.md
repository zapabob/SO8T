# SO8T統制Webスクレイピング全自動パイプライン拡張実装

## 実装情報
- **日付**: 2025-11-08
- **Worktree**: main
- **機能名**: SO8T統制Webスクレイピング全自動パイプライン拡張（チェックポイント管理、データセット作成、RAG/CoG用ベクトルストア作成）
- **実装者**: AI Agent

## 実装内容

### 1. チェックポイント管理モジュール

**ファイル**: `scripts/pipelines/checkpoint_manager.py`

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: 3分間隔でチェックポイントを保存し、最大5つのローリングストックを維持。電源投入時に既収集データを読み込まない設定を実装。

- `CheckpointManager`クラスを実装
- チェックポイント保存間隔: 180秒（3分）
- 最大チェックポイント数: 5つ（ローリングストック）
- `resume_on_startup=False`で電源投入時に既収集データを読み込まない設定
- チェックポイントデータにはサンプル、訪問済みURL、収集カウント、フェーズ情報を含む

### 2. RAG用ベクトルストアデータ作成モジュール

**ファイル**: `scripts/pipelines/vector_store_creation.py`（`RAGVectorStoreCreator`クラス）

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: クレンジング済みデータをチャンク分割し、RAG用ベクトルストアデータを作成。

- チャンクサイズ: 512文字（デフォルト）
- オーバーラップ: 128文字（デフォルト）
- JSONL形式でチャンクデータを保存
- メタデータインデックス（言語分布、ドメイン分布、カテゴリ分布）を作成
- RAG統合ガイド（ChromaDB/FAISS統合手順）を自動生成

### 3. CoG用ナレッジグラフ作成モジュール

**ファイル**: `scripts/pipelines/vector_store_creation.py`（`CoGKnowledgeGraphCreator`クラス）

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: SO8T四重推論（Task, Safety, Policy, Final）からエンティティとリレーションを抽出し、ナレッジグラフを作成。

- SO8T四重推論結果からエンティティ（PERSON, ORGANIZATION, LOCATION, CONCEPT）を抽出
- エンティティ間のリレーション（共起関係）を抽出
- ナレッジグラフを複数形式で保存:
  - JSON形式（軽量な処理・API連携用）
  - GraphML形式（NetworkX互換）
  - RDF形式（Turtle形式、SPARQLクエリ対応）
- メタデータインデックス（エンティティレイヤー分布、エンティティタイプ分布、リレーションレイヤー分布、リレーションタイプ分布）を作成
- ナレッジグラフ統合ガイド（NetworkX、Neo4j、RDF統合手順）を自動生成

### 4. データセット作成モジュール

**ファイル**: `scripts/pipelines/dataset_creator.py`

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: クレンジング済みデータからデータセットを生成。

- `DatasetCreator`クラスを実装
- JSONL形式でデータセットを保存
- メタデータ収集（カテゴリ分布、言語分布、ドメイン分布、分類分布、テキスト長統計）
- データセット情報ファイル（`*_info.json`）を自動生成
- 訓練/テスト分割機能（オプション）

### 5. 統合パイプライン拡張

**ファイル**: `scripts/pipelines/unified_auto_scraping_pipeline.py`

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: チェックポイント管理、データセット作成、RAG/CoG用ベクトルストア作成を統合パイプラインに統合。

- `CheckpointManager`を統合パイプラインに追加
- `run_dataset_creation`メソッドを追加（Phase 3）
- `run_vector_store_creation`メソッドを追加（Phase 4）
- 各フェーズでチェックポイントを保存
- パイプラインフェーズ:
  1. Phase 1: スクレイピング（チェックポイント保存）
  2. Phase 2: データクレンジング・ラベル付け・四値分類（チェックポイント保存）
  3. Phase 3: データセット作成（チェックポイント保存）
  4. Phase 4: RAG/CoG用ベクトルストア作成（チェックポイント保存）

### 6. 設定ファイル更新

**ファイル**: `configs/unified_auto_scraping_pipeline_config.yaml`

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: チェックポイント、データセット作成、RAG/CoG用ベクトルストア作成の設定を追加。

- `pipeline.resume`: `false`（電源投入時に既収集データを読み込まない）
- `pipeline.checkpoint_interval`: `180.0`（3分間隔）
- `pipeline.max_checkpoints`: `5`（5つローリングストック）
- `dataset_creation`セクションを追加
- `vector_store_creation`セクションを追加（RAG/CoG設定）

## 作成・変更ファイル
- `scripts/pipelines/checkpoint_manager.py`（新規作成）
- `scripts/pipelines/dataset_creator.py`（新規作成）
- `scripts/pipelines/vector_store_creation.py`（新規作成）
- `scripts/pipelines/unified_auto_scraping_pipeline.py`（拡張）
- `configs/unified_auto_scraping_pipeline_config.yaml`（更新）

## 設計判断

### チェックポイント管理
- **3分間隔**: データ損失を最小化しつつ、ディスクI/O負荷を抑制
- **5つローリングストック**: 十分な復旧ポイントを確保しつつ、ディスク容量を抑制
- **電源投入時に既収集データを読み込まない**: ユーザー要件に従い、常に新しいセッションとして開始

### RAG用ベクトルストア
- **チャンクサイズ512文字**: 一般的なRAG実装で使用される標準サイズ
- **オーバーラップ128文字**: コンテキストの連続性を確保
- **JSONL形式**: ストリーミング処理と並列処理に適した形式

### CoG用ナレッジグラフ
- **エンティティ抽出**: 推論テキストからエンティティ（PERSON, ORGANIZATION, LOCATION, CONCEPT）を抽出
- **リレーション抽出**: エンティティ間の共起関係をリレーションとして抽出
- **複数形式保存**: JSON、GraphML、RDF形式で保存し、様々なグラフDBやツールで利用可能に
- **レイヤー別管理**: Task, Safety, Policy, Finalの各レイヤーでエンティティとリレーションを分類

### データセット作成
- **メタデータ収集**: データセットの品質評価と統計分析を可能に
- **訓練/テスト分割**: オプション機能として実装（デフォルトは無効）

## テスト結果
- 未実施（実装完了後、統合テストが必要）

## 運用注意事項

### データ収集ポリシー
- 利用条件を守りつつ、高信頼ソースとして優先使用
- robots.txt遵守を徹底
- 個人情報・機密情報の除外を徹底

### NSFWコーパス運用
- **主目的**: 安全判定と拒否挙動の学習（生成目的ではない）
- モデル設計とドキュメントに明記
- 分類器は検出・拒否用途のみ

### /thinkエンドポイント運用
- 四重Thinking部（`<think-*>`）は外部非公開を徹底
- `<final>`のみ返す実装を維持
- 監査ログでThinkingハッシュを記録（内容は非公開）

### チェックポイント管理
- **3分間隔**: 定期的にチェックポイントを保存し、データ損失を最小化
- **5つローリングストック**: 古いチェックポイントは自動削除
- **電源投入時**: `resume_on_startup=False`により、既収集データを読み込まない

### RAG/CoG用ベクトルストア・ナレッジグラフ
- **RAG**: チャンク分割されたデータをベクトルDBにインポート可能な形式で保存
- **CoG**: SO8T四重推論からエンティティとリレーションを抽出し、ナレッジグラフを作成（JSON、GraphML、RDF形式）
- **統合ガイド**: RAGはChromaDB/FAISS統合手順、CoGはNetworkX/Neo4j/RDF統合手順を自動生成

## 次のステップ
1. 統合テストの実施
2. チェックポイントからの復旧テスト
3. RAG用ベクトルストアの実際のベクトルDBへのインポートテスト
4. CoG用ナレッジグラフのNeo4j/NetworkX/RDFへのインポートテスト
5. パフォーマンステスト（大規模データでの動作確認）
6. エンティティ抽出精度の向上（NERモデルの統合検討）

