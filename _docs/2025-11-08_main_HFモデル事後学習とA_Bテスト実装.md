# HFモデル事後学習とA/Bテスト実装ログ

## 実装情報
- **日付**: 2025-11-08
- **Worktree**: main
- **機能名**: 収集・加工済みデータでHFモデル事後学習とSO8T置き換えA/Bテスト
- **実装者**: AI Agent

## 実装内容

### 1. 収集・加工済みデータをHugging Face形式に変換

**ファイル**: `scripts/training/convert_four_class_to_hf_dataset.py` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: 四値分類データ（four_class_*.jsonl）をHugging Face Dataset形式に変換するスクリプトを実装

- `FourClassToHFDatasetConverter`クラス: データ変換クラス
- `load_jsonl_data()`: JSONLデータ読み込み
- `convert_to_hf_format()`: Hugging Face形式に変換（instruction/chat/completion形式対応）
- `tokenize_dataset()`: データセットトークナイズ
- `split_dataset()`: データセット分割（train/val/test）
- フォーマットタイプ: instruction, chat, completion
- トークナイザー自動読み込み（ベースモデルから）

### 2. Hugging FaceモデルFine-tuning

**ファイル**: `scripts/training/finetune_hf_model_with_processed_data.py` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: 収集・加工済みデータでHugging Faceモデル（Qwen2.5/Phi-3.5）をfine-tuningするスクリプトを実装

- `HFModelFinetuner`クラス: Fine-tuningクラス
- `ProcessedDataDataset`クラス: 収集・加工済みデータセット
- `PowerFailureRecovery`クラス: 電源断リカバリーシステム（5分間隔チェックポイント）
- QLoRA 8bit学習対応
- LoRA設定（r=64, alpha=128）
- 学習設定: fp16, gradient_checkpointing, paged_adamw_8bit
- チェックポイント自動保存（5分間隔）

### 3. Fine-tuningしたモデルをSO8TTransformerModelに置き換え

**ファイル**: `scripts/training/replace_so8t_with_finetuned_hf.py` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: Fine-tuningしたHugging FaceモデルをSO8Tで使用可能な形式に変換し、既存のSO8TTransformerModelと置き換える仕組みを実装

- `SO8TModelReplacer`クラス: モデル置き換えクラス
- `load_finetuned_model()`: Fine-tuningしたモデル読み込み
- `extract_model_weights()`: モデル重み抽出
- `convert_to_so8t_format()`: SO8T形式に変換
- `create_model_wrapper()`: SO8Tモデルラッパー作成
- SO8TTransformerModel互換インターフェース提供
- メタデータ保存（vocab_size, hidden_size等）

### 4. A/Bテスト実装

**ファイル**: `scripts/evaluation/ab_test_so8t_vs_finetuned_hf.py` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: 既存のSO8TTransformerModelとFine-tuningしたHugging Faceモデルを比較評価するA/Bテストを実装

- `ABTestEvaluator`クラス: A/Bテスト評価クラス
- `SO8TModelLoader`クラス: モデル読み込みクラス
- `evaluate_model_a()`: モデルA（SO8TTransformerModel）評価
- `evaluate_model_b()`: モデルB（Fine-tuned Hugging Face Model）評価
- `compare_models()`: モデル比較（accuracy, F1, latency）
- メトリクス: accuracy, F1 macro, F1 per class, precision, recall, confusion matrix, latency
- 比較結果: accuracy improvement, F1 improvement, latency change

### 5. 統合パイプライン

**ファイル**: `scripts/pipelines/finetune_and_ab_test_pipeline.py` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: データ変換、Fine-tuning、SO8T置き換え、A/Bテストを統合実行するパイプラインを実装

- `FinetuneAndABTestPipeline`クラス: 統合パイプラインクラス
- `step1_convert_data()`: ステップ1: データ変換
- `step2_finetune()`: ステップ2: Fine-tuning
- `step3_replace_so8t()`: ステップ3: SO8Tモデル置き換え
- `step4_ab_test()`: ステップ4: A/Bテスト
- `run_pipeline()`: パイプライン実行
- 各ステップの結果を保存
- 最終結果をJSON形式で保存

### 6. 設定ファイル

**ファイル**: `configs/finetune_and_ab_test_config.yaml` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: Fine-tuning & A/Bテスト統合パイプライン用設定ファイルを実装

- データ設定: input_path, format_type, max_length
- モデル設定: base_model
- 学習設定: num_train_epochs, batch_size, learning_rate, LoRA設定等
- テスト設定: test_data_path, model_a_path
- デバイス設定: device

## 作成・変更ファイル
- `scripts/training/convert_four_class_to_hf_dataset.py` (新規作成)
- `scripts/training/finetune_hf_model_with_processed_data.py` (新規作成)
- `scripts/training/replace_so8t_with_finetuned_hf.py` (新規作成)
- `scripts/evaluation/ab_test_so8t_vs_finetuned_hf.py` (新規作成)
- `scripts/pipelines/finetune_and_ab_test_pipeline.py` (新規作成)
- `configs/finetune_and_ab_test_config.yaml` (新規作成)

## 設計判断

1. **データ変換**: Hugging Face Dataset形式に変換し、instruction/chat/completion形式に対応
2. **Fine-tuning**: QLoRA 8bit学習を使用し、メモリ効率を重視
3. **モデル置き換え**: SO8TTransformerModel互換インターフェースを提供するラッパーを作成
4. **A/Bテスト**: 既存のSO8TTransformerModelとFine-tuningしたHFモデルを比較評価
5. **統合パイプライン**: 全ステップを統合実行し、結果を保存

## データフロー

```
収集・加工済みデータ（four_class_*.jsonl）
  ↓
Hugging Face Dataset形式に変換
  ↓
Hugging FaceモデルFine-tuning（QLoRA 8bit）
  ↓
SO8TTransformerModelに置き換え
  ↓
A/Bテスト（既存SO8TTransformerModel vs Fine-tuned HF Model）
  ↓
評価結果保存
```

## 依存関係

### 既存実装の活用
- ✅ `models/so8t_transformer.py` - SO8TTransformerModel
- ✅ `D:/webdataset/processed/four_class/four_class_*.jsonl` - 収集・加工済みデータ
- ✅ `scripts/evaluation/ab_test_with_hf_benchmark.py` - A/Bテスト参考実装

### 外部ライブラリ
- `transformers>=4.35.0`: Hugging Face Transformers
- `datasets>=2.14.0`: Hugging Face Datasets
- `peft>=0.6.0`: Parameter-Efficient Fine-Tuning
- `bitsandbytes>=0.41.0`: 8bit量子化
- `torch>=2.0.0`: PyTorch
- `scikit-learn>=1.3.0`: メトリクス計算

## 使用方法

### 統合パイプライン実行

```bash
# 基本実行
py scripts/pipelines/finetune_and_ab_test_pipeline.py --config configs/finetune_and_ab_test_config.yaml
```

### 個別ステップ実行

#### 1. データ変換

```bash
py scripts/training/convert_four_class_to_hf_dataset.py \
    --input D:/webdataset/processed/four_class/four_class_20251108_035137.jsonl \
    --output D:/webdataset/finetuned_models/hf_datasets \
    --base-model Qwen/Qwen2.5-7B-Instruct \
    --format instruction \
    --max-length 2048
```

#### 2. Fine-tuning

```bash
py scripts/training/finetune_hf_model_with_processed_data.py \
    --base-model Qwen/Qwen2.5-7B-Instruct \
    --dataset D:/webdataset/finetuned_models/hf_datasets/hf_dataset_instruction \
    --output D:/webdataset/finetuned_models/finetuned_models/20251108_120000 \
    --config configs/finetune_and_ab_test_config.yaml
```

#### 3. SO8Tモデル置き換え

```bash
py scripts/training/replace_so8t_with_finetuned_hf.py \
    --finetuned-model D:/webdataset/finetuned_models/finetuned_models/20251108_120000/final_model \
    --output D:/webdataset/finetuned_models/so8t_replaced_models/20251108_120000
```

#### 4. A/Bテスト

```bash
py scripts/evaluation/ab_test_so8t_vs_finetuned_hf.py \
    --model-b D:/webdataset/finetuned_models/finetuned_models/20251108_120000/final_model \
    --test-data D:/webdataset/processed/four_class/four_class_20251108_035137.jsonl \
    --output-dir eval_results/ab_test_so8t_vs_finetuned_hf \
    --device cuda
```

## テスト計画

1. **データ変換テスト**: 四値分類データのHugging Face形式変換動作確認
2. **Fine-tuningテスト**: Hugging Faceモデルのfine-tuning動作確認
3. **モデル置き換えテスト**: SO8TTransformerModel置き換え動作確認
4. **A/Bテスト**: 既存モデルとFine-tuningモデルの比較評価動作確認
5. **統合パイプラインテスト**: 全ステップ統合実行の動作確認

## 運用注意事項

### データ収集ポリシー
- 利用条件を守りつつ、高信頼ソースとして優先使用
- robots.txt遵守を徹底
- 個人情報・機密情報の除外を徹底

### NSFWコーパス運用
- **主目的**: 安全判定と拒否挙動の学習（生成目的ではない）
- モデル設計とドキュメントに明記
- 分類器は検出・拒否用途のみ

### /thinkエンドポイント運用
- 四重Thinking部（`<think-*>`）は外部非公開を徹底
- `<final>`のみ返す実装を維持
- 監査ログでThinkingハッシュを記録（内容は非公開）

## 次のステップ

1. **動作確認**: 各ステップの動作確認
2. **パフォーマンス最適化**: Fine-tuningとA/Bテストの最適化
3. **メトリクス拡張**: より詳細な評価メトリクスの追加
4. **自動化**: CI/CDパイプラインへの統合
5. **ドキュメント整備**: 詳細なドキュメント作成

