# SO8T完全統合A/Bテストパイプライン実装ログ

## 実装情報
- **日付**: 2025-11-09
- **Worktree**: main
- **機能名**: SO8T完全統合A/Bテストパイプライン
- **実装者**: AI Agent

## 実装内容

### 1. 統合パイプラインスクリプトの作成

**ファイル**: `scripts/pipelines/complete_so8t_ab_test_pipeline.py` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: Borea-Phi-3.5-mini-Instruct-Jpのmodeling_phi3_so8t.pyをそのままGGUF化したもの（Model A）と、SO8Tで再学習してデータセットでQLoRA/ファインチューニングで学習させたものをGGUF化したもの（Model B）のA/Bテストまで一気通貫で全自動実行する統合パイプライン

#### Phase 1: Model AのGGUF変換
- Borea-Phi-3.5-mini-Instruct-Jpのmodeling_phi3_so8t.pyをそのまま使用
- Hugging Face形式のままGGUF変換
- 複数の量子化形式（F16, Q8_0, Q4_K_M）をサポート
- 出力: `D:/webdataset/gguf_models/model_a/`

#### Phase 2: SO8T再学習（QLoRA/ファインチューニング）
- データセットを使用してSO8Tで再学習
- QLoRA 8bitまたはフルファインチューニングを選択可能
- 既存の`train_so8t_phi3_qlora.py`を活用
- 出力: `D:/webdataset/checkpoints/training/so8t_retrained/`

#### Phase 3: Model BのGGUF変換
- 再学習済みモデルをGGUF変換
- 複数の量子化形式（F16, Q8_0, Q4_K_M）をサポート
- 出力: `D:/webdataset/gguf_models/model_b/`

#### Phase 4: Ollamaインポート
- Model AとModel BをOllamaにインポート
- Modelfileの自動生成
- モデル名: `borea-phi35-so8t-base` (Model A), `borea-phi35-so8t-retrained` (Model B)

#### Phase 5: A/Bテスト実行
- Ollama経由での推論テスト
- 各数値の可視化
- メトリクス比較（accuracy, F1 macro, 推論速度など）
- テストサンプル数の制限（時間短縮のため）

#### Phase 6: 結果可視化とレポート生成
- グラフ・チャートの生成（Accuracy, F1 Macro, Latency比較）
- 詳細レポートの作成（Markdown形式）
- 可視化ファイル: `visualizations/metrics_comparison.png`

#### チェックポイント機能
- 各フェーズでチェックポイントを保存
- 中断から再開可能
- 処理済みフェーズをスキップ

### 2. 設定ファイルの作成

**ファイル**: `configs/complete_so8t_ab_test_pipeline_config.yaml` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: パイプラインの設定をYAMLファイルで管理

#### 設定項目
- **基本設定**: セッションID形式、出力ディレクトリ、チェックポイントディレクトリ
- **Model A設定**: ベースモデルパス、説明
- **Model B設定**: ベースモデルパス、説明
- **データセット設定**: データセットパス、フォーマット
- **学習設定**: 学習設定ファイル、QLoRA/ファインチューニング選択
- **GGUF変換設定**: 変換スクリプトパス、量子化タイプ
- **Ollama設定**: モデル名、Modelfileディレクトリ
- **A/Bテスト設定**: テストデータパス、最大サンプル数
- **可視化設定**: 出力ディレクトリ、プロット形式、DPI

### 3. GGUF変換モジュールの統合

**ファイル**: `scripts/pipelines/complete_so8t_ab_test_pipeline.py` (統合)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: 既存の`convert_hf_to_gguf.py`を活用してModel AとModel Bの両方を変換

- Phase 1でModel AをGGUF変換
- Phase 3でModel BをGGUF変換
- 複数の量子化形式（F16, Q8_0, Q4_K_M）をサポート
- サブプロセス経由で実行

### 4. SO8T再学習モジュールの統合

**ファイル**: `scripts/pipelines/complete_so8t_ab_test_pipeline.py` (統合)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: 既存の`train_so8t_phi3_qlora.py`を活用してSO8Tで再学習

- Phase 2でSO8T再学習を実行
- QLoRA 8bitまたはフルファインチューニングを選択可能
- データセットの自動検出と読み込み
- 学習設定ファイルの動的生成

### 5. A/Bテストモジュールの統合

**ファイル**: `scripts/pipelines/complete_so8t_ab_test_pipeline.py` (統合)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: Ollama経由での推論テストを実装

- Phase 5でA/Bテストを実行
- Ollama経由でModel AとModel Bの推論を実行
- メトリクス計算（accuracy, F1 macro, latency）
- テストサンプル数の制限（時間短縮のため）

### 6. 可視化モジュールの統合

**ファイル**: `scripts/pipelines/complete_so8t_ab_test_pipeline.py` (統合)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: グラフ・チャートの生成とレポート作成を実装

- Phase 6で可視化とレポート生成を実行
- Accuracy、F1 Macro、Latencyの比較チャート
- 改善率の可視化
- Markdown形式のレポート生成

### 7. バッチスクリプトの作成

**ファイル**: `scripts/pipelines/run_complete_so8t_ab_test_pipeline.bat` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [未確認]  
**確認日時**: -  
**備考**: パイプラインを簡単に実行するためのバッチスクリプト

- Pythonパスの自動検出
- 設定ファイルの指定
- ログ出力の設定
- 音声通知（完了時）

## 作成・変更ファイル
- `scripts/pipelines/complete_so8t_ab_test_pipeline.py` (新規作成)
- `configs/complete_so8t_ab_test_pipeline_config.yaml` (新規作成)
- `scripts/pipelines/run_complete_so8t_ab_test_pipeline.bat` (新規作成)
- `_docs/2025-11-09_main_SO8T完全統合A_Bテストパイプライン実装.md` (新規作成)

## 設計判断

### Model Aの作成
- **入力**: `models/Borea-Phi-3.5-mini-Instruct-Jp/`（modeling_phi3_so8t.pyを含む）
- **処理**: Hugging Face形式のままGGUF変換
- **出力**: `D:/webdataset/gguf_models/model_a/model_a_{quantization}.gguf`

### Model Bの作成
- **入力**: `models/Borea-Phi-3.5-mini-Instruct-Jp/`（modeling_phi3_so8t.pyを含む）
- **処理**: 
  1. SO8Tで再学習（QLoRA 8bitまたはフルファインチューニング）
  2. データセットで学習
  3. GGUF変換
- **出力**: `D:/webdataset/gguf_models/model_b/model_b_{quantization}.gguf`

### A/Bテスト
- **Ollama経由**: Model AとModel BをOllamaにインポートして推論テスト
- **メトリクス**: accuracy, F1 macro, 推論速度, メモリ使用量など
- **可視化**: グラフ・チャートで比較
- **レポート**: 詳細な比較レポートを生成

### チェックポイント機能
- 各フェーズでチェックポイントを保存
- 中断から再開可能
- 処理済みフェーズをスキップ

## 使用方法

### 基本的な使用方法
```bash
# バッチスクリプトを使用（推奨）
scripts\pipelines\run_complete_so8t_ab_test_pipeline.bat

# Pythonスクリプトを直接実行
py -3 scripts\pipelines\complete_so8t_ab_test_pipeline.py --config configs\complete_so8t_ab_test_pipeline_config.yaml
```

### 設定ファイルのカスタマイズ
```yaml
# configs/complete_so8t_ab_test_pipeline_config.yaml
model_a:
  base_model: "models/Borea-Phi-3.5-mini-Instruct-Jp"
model_b:
  base_model: "models/Borea-Phi-3.5-mini-Instruct-Jp"
dataset:
  paths:
    - "D:/webdataset/processed/four_class"
training:
  use_qlora: true
  use_full_finetuning: false
```

## 出力ファイル

- **Model A GGUF**: `D:/webdataset/gguf_models/model_a/model_a_{quantization}.gguf`
- **Model B GGUF**: `D:/webdataset/gguf_models/model_b/model_b_{quantization}.gguf`
- **再学習チェックポイント**: `D:/webdataset/checkpoints/training/so8t_retrained/`
- **A/Bテスト結果**: `D:/webdataset/ab_test_results/complete_so8t_ab_test_{session_id}/ab_test_results.json`
- **可視化結果**: `D:/webdataset/ab_test_results/complete_so8t_ab_test_{session_id}/visualizations/metrics_comparison.png`
- **レポート**: `D:/webdataset/ab_test_results/complete_so8t_ab_test_{session_id}/report.md`
- **チェックポイント**: `D:/webdataset/checkpoints/complete_so8t_ab_test/checkpoint_{session_id}.pkl`

## 技術詳細

### Phase 1: Model AのGGUF変換
- 既存の`convert_hf_to_gguf.py`を使用
- 複数の量子化形式をサポート
- サブプロセス経由で実行

### Phase 2: SO8T再学習
- 既存の`train_so8t_phi3_qlora.py`を使用
- QLoRA 8bitまたはフルファインチューニングを選択可能
- データセットの自動検出と読み込み

### Phase 3: Model BのGGUF変換
- Phase 1と同様の処理
- 再学習済みモデルを変換

### Phase 4: Ollamaインポート
- Modelfileの自動生成
- Ollamaへのインポート

### Phase 5: A/Bテスト
- Ollama経由で推論テスト
- メトリクス計算
- 結果の保存

### Phase 6: 可視化とレポート
- グラフ・チャートの生成
- Markdown形式のレポート生成

## 運用注意事項

### データ収集ポリシー
- 利用条件を守りつつ、高信頼ソースとして優先使用
- robots.txt遵守を徹底
- 個人情報・機密情報の除外を徹底

### NSFWコーパス運用
- **主目的**: 安全判定と拒否挙動の学習（生成目的ではない）
- モデル設計とドキュメントに明記
- 分類器は検出・拒否用途のみ

### /thinkエンドポイント運用
- 四重Thinking部（`<think-*>`）は外部非公開を徹底
- `<final>`のみ返す実装を維持
- 監査ログでThinkingハッシュを記録（内容は非公開）

### パイプライン運用
- **実行時間**: 数時間から数日かかる場合があります
- **チェックポイント**: 各フェーズで自動保存
- **再開機能**: 中断から自動的に再開可能
- **音声通知**: 各フェーズ完了時に音声通知を再生

## 次のステップ

1. **動作確認**: 実際のデータでパイプラインを実行して動作確認
2. **メトリクス改善**: A/Bテストのメトリクス計算を改善
3. **パフォーマンス最適化**: 処理速度の最適化
4. **エラーハンドリング**: エラー発生時の処理を改善
5. **統合テスト**: 他のパイプラインとの統合テスト






























































































































