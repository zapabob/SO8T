# 並列DeepResearch Webスクレイピング 実装ログ

## 実装情報
- **日付**: 2025-11-08
- **Worktree**: main
- **機能名**: 並列DeepResearch Webスクレイピング（10個のブラウザ並列実行、動的リソース管理）
- **実装者**: AI Agent

## 実装内容

### 1. 並列DeepResearch Webスクレイピングスクリプト作成

**ファイル**: `scripts/data/parallel_deep_research_scraping.py` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [実行中]  
**確認日時**: 2025-11-08 20:00:00  
**備考**: 並列で動的リソース管理を行い、10個のブラウザを起動してDeepResearchとPlaywrightでWebスクレイピングを実行するスクリプトを実装

#### 主な機能
1. **並列ブラウザ管理**
   - 10個のブラウザインスタンスを並列で起動
   - 各ブラウザが異なるキーワードを処理
   - 動的リソース管理（メモリ、CPU監視）

2. **動的リソース管理**
   - メモリ使用量の監視（最大8GB）
   - CPU使用率の監視（最大80%）
   - リソース制限に達した場合の自動調整

3. **人間を模倣した検索動作**
   - 関連キーワードの自動生成
   - 1文字ずつのタイピング（人間のような動作）
   - ランダムな待機時間
   - ボタン操作（ホバー、クリック）

4. **DeepResearch統合**
   - キーワード調査クエリの構築
   - カテゴリ別のURL生成

5. **NSFW検知統合**
   - NSFW分類器による検知（利用可能な場合）
   - ルールベース検知（フォールバック）
   - 検知目的のみ（生成目的ではない）

### 2. バッチスクリプト作成

**ファイル**: `scripts/data/run_parallel_deep_research_scraping.bat` (新規作成)

**実装状況**: [実装済み]  
**動作確認**: [OK]  
**確認日時**: 2025-11-08 20:00:00  
**備考**: 並列DeepResearch Webスクレイピングを簡単に実行するためのバッチスクリプト

### 3. リソース管理クラス

**実装状況**: [実装済み]  
**動作確認**: [実行中]  
**確認日時**: 2025-11-08 20:00:00  
**備考**: 動的リソース管理を行うResourceManagerクラスを実装

- メモリ使用量の監視
- CPU使用率の監視
- ブラウザ割り当て可能性のチェック
- リソース状態の取得

### 4. 並列ブラウザワーカー

**実装状況**: [実装済み]  
**動作確認**: [実行中]  
**確認日時**: 2025-11-08 20:00:00  
**備考**: 各ブラウザが独立してキーワードを処理するワーカーを実装

- キーワードキューからの取得
- 重複チェック
- スクレイピング実行
- リソース状態のログ出力

### 5. 人間を模倣した動作

**実装状況**: [実装済み]  
**動作確認**: [実行中]  
**確認日時**: 2025-11-08 20:00:00  
**備考**: 人間を模倣した検索動作とボタン操作を実装

- **検索動作**: 1文字ずつのタイピング、ランダムな待機時間
- **ボタン操作**: ホバー、クリック、ランダムな選択
- **関連キーワード検索**: 自動生成された関連キーワードで検索

## 作成・変更ファイル
- `scripts/data/parallel_deep_research_scraping.py` (新規作成)
- `scripts/data/run_parallel_deep_research_scraping.bat` (新規作成)
- `_docs/2025-11-08_main_並列DeepResearchWebスクレイピング実装.md` (新規作成)

## 設計判断

1. **並列処理**: 10個のブラウザを並列で起動して効率的にスクレイピング
2. **動的リソース管理**: メモリとCPUを監視してリソース制限を管理
3. **人間を模倣した動作**: ボット検知を回避するため、自然な動作パターンを実装
4. **キーワードキュー管理**: 重複を避けつつ、効率的にキーワードを処理

## テスト結果

### 実行結果
- **実行時刻**: 2025-11-08 20:00:00
- **実行状態**: バックグラウンドで実行中
- **設定**: 
  - 並列ブラウザ数: 10
  - 最大メモリ: 8.0GB
  - 最大CPU: 80.0%
  - キーワードあたり最大ページ数: 5

### 収集対象
- **日本語**: 6カテゴリ × 約20キーワード/カテゴリ = 約120キーワード
- **英語**: 6カテゴリ × 約20キーワード/カテゴリ = 約120キーワード
- **合計**: 約240キーワード

## 使用方法

### 基本的な使用方法
```bash
# デフォルト設定で実行（10個のブラウザ）
py -3 scripts\data\parallel_deep_research_scraping.py --output D:\webdataset\processed

# カスタム設定で実行
py -3 scripts\data\parallel_deep_research_scraping.py \
    --output D:\webdataset\processed \
    --num-browsers 10 \
    --max-memory-gb 8.0 \
    --max-cpu-percent 80.0 \
    --delay 1.5
```

### バッチスクリプト使用
```bash
scripts\data\run_parallel_deep_research_scraping.bat
```

## パラメータ説明

- `--output`: 出力ディレクトリ（デフォルト: D:\webdataset\processed）
- `--num-browsers`: 並列ブラウザ数（デフォルト: 10）
- `--use-cursor-browser`: Cursorブラウザを使用（デフォルト: true）
- `--remote-debugging-port`: リモートデバッグポート（ベースポート、デフォルト: 9222）
- `--delay`: アクション間の遅延（秒、デフォルト: 1.5）
- `--timeout`: ページ読み込みタイムアウト（ミリ秒、デフォルト: 30000）
- `--max-pages-per-keyword`: キーワードあたりの最大ページ数（デフォルト: 5）
- `--max-memory-gb`: 最大メモリ使用量（GB、デフォルト: 8.0）
- `--max-cpu-percent`: 最大CPU使用率（%、デフォルト: 80.0）

## 出力ファイル

- **並列スクレイピングデータ**: `D:\webdataset\processed\parallel_deep_research_scraped_{session_id}.jsonl`
- **NSFW検知データ**: `D:\webdataset\processed\nsfw_detected_{session_id}.jsonl`（検知された場合）

## 技術詳細

### 並列処理アーキテクチャ
```
Playwright
  ├── Browser 1 (Worker 1) → Keyword Queue → Scraping
  ├── Browser 2 (Worker 2) → Keyword Queue → Scraping
  ├── Browser 3 (Worker 3) → Keyword Queue → Scraping
  ├── ...
  └── Browser 10 (Worker 10) → Keyword Queue → Scraping
```

### リソース管理フロー
1. ブラウザワーカー起動
2. リソース状態をチェック
3. リソース制限内であればキーワード処理
4. リソース制限に達した場合は待機
5. 定期的にリソース状態をログ出力

### 人間を模倣した動作フロー
1. 検索エンジンに移動
2. 検索ボックスをクリック
3. 1文字ずつタイピング（ランダムな遅延）
4. Enterキーで検索
5. 関連キーワードで検索
6. ボタン操作（ホバー、クリック）
7. ページコンテンツを抽出

## 運用注意事項

### データ収集ポリシー
- 利用条件を守りつつ、高信頼ソースとして優先使用
- robots.txt遵守を徹底
- 個人情報・機密情報の除外を徹底

### NSFWコーパス運用
- **主目的**: 安全判定と拒否挙動の学習（生成目的ではない）
- モデル設計とドキュメントに明記
- 分類器は検出・拒否用途のみ
- NSFWデータは検知目的のみで、生成目的ではないことを明記

### /thinkエンドポイント運用
- 四重Thinking部（`<think-*>`）は外部非公開を徹底
- `<final>`のみ返す実装を維持
- 監査ログでThinkingハッシュを記録（内容は非公開）

### リソース管理
- メモリ使用量を定期的に監視
- CPU使用率を定期的に監視
- リソース制限に達した場合は自動調整
- システムリソースを適切に管理

## 次のステップ

1. **動作確認**: 実行中のスクレイピングの動作を確認
2. **リソース最適化**: メモリとCPUの使用量を最適化
3. **パフォーマンス改善**: 並列処理の効率を向上
4. **エラーハンドリング**: エラー発生時の処理を改善

